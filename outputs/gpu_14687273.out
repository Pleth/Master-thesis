Mon Nov  7 13:40:38 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:37:00.0 Off |                    0 |
| N/A   33C    P0    25W / 250W |      0MiB / 16384MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-PCIE-16GB"
  CUDA Driver Version / Runtime Version          11.7 / 11.6
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 16161 MBytes (16945709056 bytes)
  (080) Multiprocessors, (064) CUDA Cores/MP:    5120 CUDA Cores
  GPU Max Clock rate:                            1380 MHz (1.38 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 7 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 55 / 0
  Compute Mode:
     < Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.7, CUDA Runtime Version = 11.6, NumDevs = 1
Result = PASS
Deep_google
batch_size =  128 lr =  1e-06 wd =  1.0
5275 1164 1134
cuda:0
1 3.174347438224684
2 2.1962484178949873
3 1.737018856527681
4 1.5157171546791401
5 1.3573587009692079
6 1.261598787793616
7 1.1733692596647978
8 1.1249103737216426
9 1.1071692417018222
10 1.0877071200614856
Train R2 - DI: 0.107
Val R2 - DI: 0.079
Test R2 - DI: 0.326
11 1.0809411113522065
12 1.064692258687946
13 1.039173197701079
14 1.0130826779225426
15 1.0252920636972545
16 1.038107937896421
17 1.002272926755426
18 0.9864090183334893
19 0.9877225157660896
20 1.0034683329008203
Train R2 - DI: 0.195
Val R2 - DI: 0.095
Test R2 - DI: 0.380
21 0.9872668717935752
22 1.0006394918496009
23 0.9721219363709762
24 0.9725888366608824
25 0.9627522386758813
26 0.964922587713359
27 0.9706396379968001
28 0.9497235470699473
29 0.9404934277918666
30 0.9516284210874006
Train R2 - DI: 0.223
Val R2 - DI: 0.114
Test R2 - DI: 0.399
31 0.9511375360353298
32 0.9564486413996367
33 0.9451432697015916
34 0.9227914444078201
35 0.9330902387745572
36 0.9333213064455873
37 0.9276384192055436
38 0.9187462615740808
39 0.9242926250475842
40 0.9063960466791668
Train R2 - DI: 0.243
Val R2 - DI: 0.132
Test R2 - DI: 0.413
41 0.9203360003430696
42 0.8951883055135537
43 0.9032086070792935
44 0.893019993519896
45 0.9118828055078949
46 0.8892508223384478
47 0.9052116247827973
48 0.8849440671821341
49 0.8901230381563376
50 0.8912727783641544
Train R2 - DI: 0.268
Val R2 - DI: 0.120
Test R2 - DI: 0.422
51 0.884823361347072
52 0.8844251197322285
53 0.8915407480334784
54 0.8725871947817327
55 0.8752788588447028
56 0.8677430427469913
57 0.8664108936255577
58 0.8613940263415965
59 0.8644638874124012
60 0.873775154979308
Train R2 - DI: 0.281
Val R2 - DI: 0.139
Test R2 - DI: 0.435
61 0.8603006353197504
62 0.8491818929961508
63 0.8811412638397579
64 0.8424225141877811
65 0.8584250140755098
66 0.8568881338693519
67 0.8423121282500678
68 0.8449485688977897
69 0.8456233201433697
70 0.8452499488631696
Train R2 - DI: 0.298
Val R2 - DI: 0.130
Test R2 - DI: 0.446
71 0.8405001548455224
72 0.8398312644370924
73 0.8523864044397363
74 0.8286288284577464
75 0.8295255615473923
76 0.8246383234787892
77 0.8304037207110798
78 0.8354249642132583
79 0.8303852701300128
80 0.8394138802736292
Train R2 - DI: 0.312
Val R2 - DI: 0.137
Test R2 - DI: 0.446
81 0.8246658664631052
82 0.8315087734127496
83 0.8255355308180172
84 0.8081808109871019
85 0.8124085283109928
86 0.8102768505354063
87 0.8176167535555872
88 0.8104687204519154
89 0.805255864739983
90 0.8061062740262651
Train R2 - DI: 0.323
Val R2 - DI: 0.127
Test R2 - DI: 0.456
91 0.8063386361180889
92 0.802082377869936
93 0.8048379639426679
94 0.8055946841398122
95 0.8021037142084673
96 0.7898942738912682
97 0.7921295516976813
98 0.7833159481518641
99 0.7919295724308322
100 0.8062822735253103
Train R2 - DI: 0.330
Val R2 - DI: 0.127
Test R2 - DI: 0.465
101 0.7863546552138306
102 0.791520334420046
103 0.7833280057590719
104 0.7854347330812029
105 0.7772040590403769
106 0.7956903841710203
107 0.781463539815062
108 0.7822456898790965
109 0.7754019949334493
110 0.774853534517695
Train R2 - DI: 0.343
Val R2 - DI: 0.138
Test R2 - DI: 0.459
111 0.7798212430262452
112 0.7736084343810782
113 0.7753636949548224
114 0.7682792539054184
115 0.7615427061844776
116 0.7568075417907317
117 0.7687158809792939
118 0.7571123858650713
119 0.7701171652287668
120 0.7660346554466898
Train R2 - DI: 0.355
Val R2 - DI: 0.122
Test R2 - DI: 0.466
121 0.7719679277429083
122 0.7761318987127729
123 0.7623733706496904
124 0.7606194070617169
125 0.7664782638685398
126 0.756025148342006
127 0.7506011198030264
128 0.7459190348087329
129 0.7475882449760256
130 0.751506996493769
Train R2 - DI: 0.362
Val R2 - DI: 0.129
Test R2 - DI: 0.470
131 0.7480772213122291
132 0.7595691818874594
133 0.7551021796493169
134 0.7550847227087518
135 0.7419708702010566
136 0.746947420332669
137 0.7370699397308567
138 0.7282481113768302
139 0.7362735661963151
140 0.7341407042318046
Train R2 - DI: 0.372
Val R2 - DI: 0.116
Test R2 - DI: 0.470
141 0.7434094422292935
142 0.7369003476689777
143 0.7307309317362817
144 0.7375525056016389
145 0.7345622867882534
146 0.7260956188965748
147 0.7361752666794293
148 0.726432185500719
149 0.7375929564209346
150 0.7166993330214261
Train R2 - DI: 0.383
Val R2 - DI: 0.106
Test R2 - DI: 0.470
0.13908007272079204
Deep_google
batch_size =  128 lr =  1e-06 wd =  10.0
5275 1164 1134
cuda:0
1 4.151578693344694
2 3.7880978183836733
3 3.5107846467302872
4 3.2376568778883223
5 3.036957923834923
6 2.95304997482571
7 2.749572216006817
8 2.654066507669422
9 2.555816172061938
10 2.4375952333296644
Train R2 - DI: -1.087
Val R2 - DI: -0.777
Test R2 - DI: -0.538
11 2.3449136622370137
12 2.276184129647169
13 2.193503212454195
14 2.159979347391716
15 2.1313990315441838
16 2.029731721041892
17 2.0030168073437227
18 1.9619753867868
19 1.9135384035336462
20 1.8835428348649734
Train R2 - DI: -0.623
Val R2 - DI: -0.384
Test R2 - DI: -0.175
21 1.8010976743472131
22 1.7679862837090876
23 1.7570888152506678
24 1.7754369197863538
25 1.7071166702695368
26 1.6889628674068722
27 1.6398110675811768
28 1.625603474418134
29 1.6271184449399252
30 1.591851568787019
Train R2 - DI: -0.383
Val R2 - DI: -0.200
Test R2 - DI: 0.002
31 1.577903725276061
32 1.5295996628214397
33 1.5237473061073448
34 1.519878655971509
35 1.4963975207613542
36 1.4733036747927915
37 1.4459135982549587
38 1.4531513178405038
39 1.3989672932918602
40 1.4100528043141298
Train R2 - DI: -0.240
Val R2 - DI: -0.095
Test R2 - DI: 0.098
41 1.3922597324678683
42 1.3664789554180128
43 1.3732085892374482
44 1.3730000501786364
45 1.3580957160741798
46 1.3595881544809205
47 1.3278632762872777
48 1.3214028004786416
49 1.324956803412234
50 1.2966358614193885
Train R2 - DI: -0.120
Val R2 - DI: -0.023
Test R2 - DI: 0.182
51 1.284638649434275
52 1.2891241651462717
53 1.279576950638215
54 1.2683661198955012
55 1.2465664137144223
56 1.2583925205836364
57 1.230252624755787
58 1.2476456843055255
59 1.242228353193021
60 1.2264742393629247
Train R2 - DI: -0.071
Val R2 - DI: 0.010
Test R2 - DI: 0.214
61 1.2265664231042726
62 1.223737491148908
63 1.2019672168261633
64 1.1937362903102315
65 1.201691366733533
66 1.1874529463419983
67 1.1777605167610385
68 1.1908861293159956
69 1.1847946500213224
70 1.1724452346422096
Train R2 - DI: -0.002
Val R2 - DI: 0.043
Test R2 - DI: 0.261
71 1.188208819915898
72 1.163324770181665
73 1.148614188551338
74 1.158105649970719
75 1.1447046376630594
76 1.1377549258453585
77 1.1339961985502198
78 1.1370062242526013
79 1.1341501043645126
80 1.1271214865282249
Train R2 - DI: -0.005
Val R2 - DI: 0.043
Test R2 - DI: 0.272
81 1.126183446640087
82 1.1192740408956157
83 1.1011048550741367
84 1.1026731658546844
85 1.1121922758970215
86 1.098572998318062
87 1.1182328380566637
88 1.101978995449735
89 1.1193323348935746
90 1.0973769104424247
Train R2 - DI: 0.053
Val R2 - DI: 0.070
Test R2 - DI: 0.302
91 1.0850804321686804
92 1.0881194636494063
93 1.0888482504433366
94 1.0881884832291806
95 1.076561030482794
96 1.0737236870634612
97 1.0611751992555591
98 1.0652383857428744
99 1.068419014492306
100 1.0635862380294439
Train R2 - DI: 0.071
Val R2 - DI: 0.081
Test R2 - DI: 0.311
101 1.0640296122248138
102 1.0512448953565263
103 1.0662366403561632
104 1.0646429800761255
105 1.058724970252593
106 1.045746058536367
107 1.0493638119200395
108 1.0352134812160692
109 1.044438122008084
110 1.036674873659396
Train R2 - DI: 0.084
Val R2 - DI: 0.090
Test R2 - DI: 0.320
111 1.0506375239358694
112 1.053060297683517
113 1.0491026314061964
114 1.0412585790688393
115 1.0342041454721966
116 1.026447925793616
117 1.024664907670134
118 1.0198554174481975
119 1.0282674639597889
120 1.0166920360230722
Train R2 - DI: 0.102
Val R2 - DI: 0.100
Test R2 - DI: 0.329
121 1.0219918569908324
122 1.0186825521071374
123 1.0108115112951017
124 1.0050037756576358
125 1.0099458579429519
126 1.0109913929491812
127 1.0184827274846804
128 0.9997917797215177
129 1.003900613558801
130 1.0109463683349826
Train R2 - DI: 0.122
Val R2 - DI: 0.105
Test R2 - DI: 0.343
131 1.003194215715779
132 0.9896225506773492
133 0.981910967623453
134 0.9892321472484353
135 1.0021102628436698
136 0.9971956659380293
137 0.9931321506816629
138 0.9999725365299749
139 0.9944521334498979
140 0.9794446559539903
Train R2 - DI: 0.139
Val R2 - DI: 0.113
Test R2 - DI: 0.347
141 0.9733512951525467
142 0.9758808235082581
143 1.0018295928991237
144 0.9787534860525086
145 0.9805182407478585
146 0.9767762197250438
147 0.9774605028493709
148 0.981033508619426
149 0.9794966562325356
150 0.9724624954015723
Train R2 - DI: 0.149
Val R2 - DI: 0.115
Test R2 - DI: 0.364
0.11491947289058246
Deep_google
batch_size =  128 lr =  1e-06 wd =  100.0
5275 1164 1134
cuda:0
1 3.975147561439406
2 3.916410490867651
3 3.8911016702425987
4 3.8413670512737257
5 3.808037882981142
6 3.745764109263488
7 3.727925229547148
8 3.6917999919330904
9 3.6584063473922948
10 3.625974095285786
Train R2 - DI: -2.312
Val R2 - DI: -1.930
Test R2 - DI: -1.542
11 3.5876834198648897
12 3.5796268713078794
13 3.544869080584196
14 3.5401103747399496
15 3.465476719779426
16 3.465195583777405
17 3.410159096650038
18 3.4104544159134416
19 3.375273804596815
20 3.393171745047185
Train R2 - DI: -2.074
Val R2 - DI: -1.689
Test R2 - DI: -1.326
21 3.3492614051855005
22 3.3396007040665614
23 3.3229167868627756
24 3.270705773593125
25 3.2829501190456734
26 3.2740552336796767
27 3.2383951135608258
28 3.209456124961094
29 3.2253579075980525
30 3.198000231693141
Train R2 - DI: -1.895
Val R2 - DI: -1.511
Test R2 - DI: -1.170
31 3.1555739622432473
32 3.152614939721275
33 3.1272406265294945
34 3.1464094307524335
35 3.1369119796029765
36 3.0924301399664857
37 3.0771506479905115
38 3.0749222031362815
39 3.042747641197313
40 3.050515209035286
Train R2 - DI: -1.785
Val R2 - DI: -1.400
Test R2 - DI: -1.067
41 3.024560755237019
42 3.0112872264509516
43 2.9993153447336494
44 2.9579440368634264
45 2.963265322915751
46 2.9535592443909127
47 2.9372425937652586
48 2.93516158289254
49 2.915151059028662
50 2.9323198841872373
Train R2 - DI: -1.748
Val R2 - DI: -1.374
Test R2 - DI: -1.071
51 2.9141963001450093
52 2.909360013753882
53 2.8743614081070885
54 2.9118295791589817
55 2.8734464585272623
56 2.832435710690033
57 2.8412024587025573
58 2.845251184888361
59 2.832527962047342
60 2.840647623098292
Train R2 - DI: -1.564
Val R2 - DI: -1.189
Test R2 - DI: -0.877
61 2.8188616738161203
62 2.796710071202138
63 2.7609526958736765
64 2.7911028951039247
65 2.780245352378954
66 2.747021099199051
67 2.7658342308568726
68 2.767202144098508
69 2.7399907637772403
70 2.7449655573062985
Train R2 - DI: -1.512
Val R2 - DI: -1.144
Test R2 - DI: -0.850
71 2.725078900188066
72 2.720693484934585
73 2.7007238352355234
74 2.725514393485553
75 2.6939694882343166
76 2.68347409646093
77 2.6815364892335865
78 2.6726369860047976
79 2.659308075362472
80 2.673826850556649
Train R2 - DI: -1.462
Val R2 - DI: -1.099
Test R2 - DI: -0.818
81 2.6735582862872085
82 2.651604670822903
83 2.6217259408399394
84 2.6333103792814283
85 2.6414974296714457
86 2.6108945964523964
87 2.6245989465035535
88 2.5871545992756344
89 2.6040176287194563
90 2.589496075734143
Train R2 - DI: -1.419
Val R2 - DI: -1.058
Test R2 - DI: -0.784
91 2.5826872942684953
92 2.583390633641826
93 2.5704691556053705
94 2.5795195410714897
95 2.5680240003757566
96 2.5560881799318214
97 2.562893636079761
98 2.5425074059816333
99 2.5393259491852676
100 2.5346574080046884
Train R2 - DI: -1.360
Val R2 - DI: -1.004
Test R2 - DI: -0.733
101 2.5477030097364812
102 2.544244918913638
103 2.530318144170029
104 2.5232120015835875
105 2.5152147597724226
106 2.514535975478837
107 2.5124476070765636
108 2.4987397173117687
109 2.488454793008018
110 2.489707541849941
Train R2 - DI: -1.308
Val R2 - DI: -0.957
Test R2 - DI: -0.688
111 2.4786461355109917
112 2.4749026924738953
113 2.4836340215420836
114 2.4663399055896775
115 2.4695262458765113
116 2.4360939605993117
117 2.4806174803910097
118 2.4499649487174517
119 2.4676259997670686
120 2.455388361017851
Train R2 - DI: -1.306
Val R2 - DI: -0.959
Test R2 - DI: -0.706
121 2.4499401159422094
122 2.4310470321619113
123 2.4498974335024144
124 2.4381390260633133
125 2.4092697199148025
126 2.4350063393579275
127 2.4289483864499495
128 2.4188423687360863
129 2.4245516289579925
130 2.402077975566918
Train R2 - DI: -1.261
Val R2 - DI: -0.916
Test R2 - DI: -0.661
131 2.394932417033408
132 2.4042709896123804
133 2.4001044051003118
134 2.3775331812447282
135 2.397407543331526
136 2.3965757181972123
137 2.3960220993186625
138 2.385241197680975
139 2.395108668928463
140 2.3668506219149767
Train R2 - DI: -1.208
Val R2 - DI: -0.869
Test R2 - DI: -0.610
141 2.376842890282943
142 2.382330302378578
143 2.387609965179769
144 2.375546007065976
145 2.3573808658744486
146 2.3704776727305767
147 2.3569462934376504
148 2.3546155438716942
149 2.3500734821428053
150 2.346298452485794
Train R2 - DI: -1.226
Val R2 - DI: -0.890
Test R2 - DI: -0.648
-0.8689185118967055

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 14687273: <testjob> in cluster <dcc> Exited

Job <testjob> was submitted from host <n-62-27-23> by user <s174503> in cluster <dcc> at Mon Nov  7 13:40:36 2022
Job was executed on host(s) <n-62-20-3>, in queue <gpuv100>, as user <s174503> in cluster <dcc> at Mon Nov  7 13:40:38 2022
</zhome/fd/6/127382> was used as the home directory.
</zhome/fd/6/127382/Desktop/MasterThesis/Master-thesis> was used as the working directory.
Started at Mon Nov  7 13:40:38 2022
Terminated at Mon Nov  7 16:15:48 2022
Results reported at Mon Nov  7 16:15:48 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J testjob
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 10:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -o outputs/gpu_%J.out
#BSUB -e outputs/errors/gpu_%J.err

nvidia-smi
module load cuda/11.6

/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery

source $HOME/miniconda3/bin/activate
source venv_1/bin/activate

python3 main.py Deep_google 128 1e-6 1 150 t6
python3 main.py Deep_google 128 1e-6 10 150 t7
python3 main.py Deep_google 128 1e-6 100 150 t8

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   7301.32 sec.
    Max Memory :                                 2277 MB
    Average Memory :                             2195.53 MB
    Total Requested Memory :                     5120.00 MB
    Delta Memory :                               2843.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   9397 sec.
    Turnaround time :                            9312 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/errors/gpu_14687273.err> for stderr output of this job.

