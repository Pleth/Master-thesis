Tue Nov 15 21:22:01 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   42C    P0    43W / 300W |      0MiB / 32768MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-SXM2-32GB"
  CUDA Driver Version / Runtime Version          11.8 / 11.6
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 32511 MBytes (34089926656 bytes)
  (080) Multiprocessors, (064) CUDA Cores/MP:    5120 CUDA Cores
  GPU Max Clock rate:                            1530 MHz (1.53 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 5 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 59 / 0
  Compute Mode:
     < Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.8, CUDA Runtime Version = 11.6, NumDevs = 1
Result = PASS
CNN_simple
batch_size =  128 lr =  1e-06 wd =  5.0
5580 1000 1000
cuda:0
Using SGD
1 2.812359612646069
2 1.9096755331989685
3 1.5680250958302542
4 1.4110944181360223
5 1.3144775258170234
6 1.2537614581405476
7 1.2198628587107505
8 1.1679440829061694
9 1.132734031019245
10 1.12280946824713
Train R2 - DI: 0.032
Val R2 - DI: -0.059
Test R2 - DI: 0.006
11 1.0980160070576548
12 1.0790287761705324
13 1.0804690621659747
14 1.0538245588220576
15 1.0438171970374268
16 1.0531415908567368
17 1.028180317895814
18 1.0176831112967597
19 1.0147619135918156
20 1.0223105226366322
Train R2 - DI: 0.135
Val R2 - DI: 0.065
Test R2 - DI: 0.108
21 1.0154431723351973
22 0.99704904530638
23 0.9938581737138892
24 0.9720350131339069
25 0.9733346834404921
26 0.974751966486695
27 0.9695631359213142
28 0.9643988788341535
29 0.9606243291636094
30 0.94822086352174
Train R2 - DI: 0.181
Val R2 - DI: 0.119
Test R2 - DI: 0.151
31 0.9484509005341478
32 0.9512284286987824
33 0.94191967693281
34 0.9411993202342782
35 0.9278240731112846
36 0.9365521784751646
37 0.9248285317933688
38 0.9304460663094742
39 0.9064279128573701
40 0.9215276723694203
Train R2 - DI: 0.214
Val R2 - DI: 0.157
Test R2 - DI: 0.181
41 0.9182673010774838
42 0.9105600450628547
43 0.9125040801622535
44 0.9056195138175855
45 0.9021672348395043
46 0.8950321461564751
47 0.8938790151295268
48 0.8963318952522825
49 0.9028027273420792
50 0.9044731759255932
Train R2 - DI: 0.236
Val R2 - DI: 0.180
Test R2 - DI: 0.202
51 0.8984945257932054
52 0.8857402335785624
53 0.8813376375423965
54 0.8884527309821071
55 0.8955344551353044
56 0.8933111155759477
57 0.8851788111912307
58 0.8691871802866673
59 0.8788278594666484
60 0.8638868970255698
Train R2 - DI: 0.251
Val R2 - DI: 0.196
Test R2 - DI: 0.217
61 0.8640360159685962
62 0.8658664682005469
63 0.8612487069167544
64 0.8616510888154362
65 0.8695506996151366
66 0.8647106145445164
67 0.8674583949923088
68 0.8596611789477768
69 0.8524494935962035
70 0.8473180066727396
Train R2 - DI: 0.264
Val R2 - DI: 0.209
Test R2 - DI: 0.228
71 0.8507405296448738
72 0.8476798880484796
73 0.847133222104828
74 0.8681385828175425
75 0.845012595106624
76 0.8490413881544571
77 0.8462568552263321
78 0.8401880000654515
79 0.836137582238857
80 0.8392568804884469
Train R2 - DI: 0.275
Val R2 - DI: 0.220
Test R2 - DI: 0.238
81 0.844560515538766
82 0.8392154346657483
83 0.8570904851814325
84 0.839241595678432
85 0.8345555773345373
86 0.8361704441381612
87 0.8332201859002473
88 0.8116052228490084
89 0.8396704194366291
90 0.8302637818893651
Train R2 - DI: 0.281
Val R2 - DI: 0.228
Test R2 - DI: 0.242
91 0.8365822483134526
92 0.8344901337418505
93 0.8244429502008637
94 0.8246469901454064
95 0.8285730998148627
96 0.8266780198261302
97 0.8298694874650688
98 0.8189599107243254
99 0.8328916233072998
100 0.8301533440962487
Train R2 - DI: 0.291
Val R2 - DI: 0.235
Test R2 - DI: 0.252
101 0.8248807675522288
102 0.824100085954085
103 0.8300073728339219
104 0.8283757718233224
105 0.8197927175884179
106 0.8165726522390988
107 0.8136136834766703
108 0.8094866282623728
109 0.818179343080008
110 0.8184164356159908
Train R2 - DI: 0.297
Val R2 - DI: 0.242
Test R2 - DI: 0.259
111 0.8074487628475312
112 0.8165901938219652
113 0.8135340402630495
114 0.8243010889672037
115 0.7975640758391349
116 0.8114062648947521
117 0.7972735911287288
118 0.8093931453202361
119 0.7981391548683139
120 0.8163783614353467
Train R2 - DI: 0.303
Val R2 - DI: 0.245
Test R2 - DI: 0.263
121 0.8036871578103753
122 0.8088814097920626
123 0.8022634519471062
124 0.8052222716765591
125 0.8101802019235481
126 0.8033095038919893
127 0.801853579261397
128 0.809421558363036
129 0.8022797628115582
130 0.8040718135867923
Train R2 - DI: 0.309
Val R2 - DI: 0.250
Test R2 - DI: 0.267
131 0.7939980251387456
132 0.7970927963547382
133 0.8003865810705342
134 0.7965145653293979
135 0.7915780112734833
136 0.7947390111116526
137 0.7998848042180461
138 0.7950984657878944
139 0.7990222266070731
140 0.7966069333869497
Train R2 - DI: 0.312
Val R2 - DI: 0.253
Test R2 - DI: 0.268
141 0.8042021337375846
142 0.7893058629873405
143 0.8024562999339087
144 0.805075535466594
145 0.7972686645377921
146 0.7835748622067086
147 0.7878045621311366
148 0.7870551817733327
149 0.7909423201742138
150 0.7826941682446388
Train R2 - DI: 0.316
Val R2 - DI: 0.255
Test R2 - DI: 0.271
151 0.7962316094760826
152 0.784802442639532
153 0.7854660351216579
154 0.7863688927397505
155 0.7909938401646084
156 0.7892815255776956
157 0.788835581870062
158 0.7832670155819171
159 0.7862728967461535
160 0.7902736240390381
Train R2 - DI: 0.320
Val R2 - DI: 0.259
Test R2 - DI: 0.272
161 0.7872593729299456
162 0.7755727760680687
163 0.7771307324423158
164 0.7819029973826528
165 0.7747323847158836
166 0.788226426203191
167 0.7886379661525876
168 0.789008279598742
169 0.7845624580605483
170 0.7753582915952129
Train R2 - DI: 0.322
Val R2 - DI: 0.260
Test R2 - DI: 0.275
171 0.7934776377934282
172 0.7885599162843492
173 0.7756462005731453
174 0.777229951957648
175 0.7818692948655843
176 0.7848772033995625
177 0.7789709657751104
178 0.7759918401318212
179 0.7637887236465263
180 0.770481215753863
Train R2 - DI: 0.327
Val R2 - DI: 0.265
Test R2 - DI: 0.280
181 0.7772175873479535
182 0.783405097710189
183 0.7717353526409382
184 0.7712643440906293
185 0.7754350739995212
186 0.7827334266836925
187 0.7794524720492756
188 0.7700410469031248
189 0.7696335630177596
190 0.7667977132250331
Train R2 - DI: 0.330
Val R2 - DI: 0.265
Test R2 - DI: 0.280
191 0.7732294090759797
192 0.7669622904083635
193 0.7760846246100669
194 0.7665370286579201
195 0.7708946924055776
196 0.7652359062625516
197 0.778035300094167
198 0.7588712650815218
199 0.7752013397045887
200 0.7772198227144057
Train R2 - DI: 0.329
Val R2 - DI: 0.265
Test R2 - DI: 0.283
201 0.7619481160221988
202 0.7541004470599595
203 0.7676642057716205
204 0.7569456367082493
205 0.7636986110372782
206 0.7698644738470781
207 0.7692333960618597
208 0.7604311458953392
209 0.7649171867678243
210 0.7661638636742869
Train R2 - DI: 0.335
Val R2 - DI: 0.269
Test R2 - DI: 0.281
211 0.762858647300351
212 0.7574993052790242
213 0.7658204451684029
214 0.7692070859307457
215 0.7647992833113585
216 0.7663302570260981
217 0.7544076747364468
218 0.754234408050455
219 0.7681759880862356
220 0.7638028424700528
Train R2 - DI: 0.336
Val R2 - DI: 0.271
Test R2 - DI: 0.284
221 0.7656763917229081
222 0.7562081993694374
223 0.7678490153350284
224 0.7604119595233685
225 0.7647525048597739
226 0.7602225242977074
227 0.7683501964401601
228 0.7547688896938037
229 0.7614141795797588
230 0.7584661014191139
Train R2 - DI: 0.341
Val R2 - DI: 0.273
Test R2 - DI: 0.289
231 0.7639801491118674
232 0.7612003543470923
233 0.7602699022139272
234 0.756462980256713
235 0.7452836499846537
236 0.7584599840171021
237 0.7518878994876765
238 0.7603270441400535
239 0.7570665039896538
240 0.7556424541712662
Train R2 - DI: 0.340
Val R2 - DI: 0.273
Test R2 - DI: 0.285
241 0.7676891543959204
242 0.7586096544846839
243 0.7557341617922629
244 0.7542833529920133
245 0.7533260277522508
246 0.7486868133681649
247 0.7564391787334155
248 0.750795799472426
249 0.7491699796850964
250 0.7476824554063941
Train R2 - DI: 0.343
Val R2 - DI: 0.276
Test R2 - DI: 0.291
251 0.7513947747086966
252 0.7526112338548065
253 0.7488423354309519
254 0.7527076075153966
255 0.7523271781569313
256 0.760134826509756
257 0.7555137384322381
258 0.7522304027311264
259 0.7523251624517543
260 0.7504525433731762
Train R2 - DI: 0.346
Val R2 - DI: 0.277
Test R2 - DI: 0.290
261 0.7589828160074023
262 0.7489608410438756
263 0.7489435736851026
264 0.7466747396735735
265 0.753237082966767
266 0.7485482614527467
267 0.7427812538266609
268 0.748932508670301
269 0.7584131849709378
270 0.743892416817313
Train R2 - DI: 0.348
Val R2 - DI: 0.278
Test R2 - DI: 0.294
271 0.7380917173559948
272 0.7549059192339579
273 0.7400345588029499
274 0.7421286252237136
275 0.7521124266809033
276 0.7533698016597379
277 0.7405042103114521
278 0.7480990733297068
279 0.7443331744935777
280 0.749493449691376
Train R2 - DI: 0.348
Val R2 - DI: 0.278
Test R2 - DI: 0.292
281 0.7494211556236376
282 0.7403231060205822
283 0.7450564393005918
284 0.7495916730186846
285 0.7439333146618259
286 0.7416967101421835
287 0.7404427906518342
288 0.7470354909965214
289 0.7489494147266539
290 0.7538079507462013
Train R2 - DI: 0.353
Val R2 - DI: 0.281
Test R2 - DI: 0.293
291 0.7470511240771167
292 0.7444668736081824
293 0.7497668383796583
294 0.7395044499400696
295 0.7419777871887316
296 0.7527616880700579
297 0.7477586039505552
298 0.7388834482452775
299 0.7574058831806251
300 0.7405382603300088
Train R2 - DI: 0.353
Val R2 - DI: 0.280
Test R2 - DI: 0.294
301 0.7450806525445753
302 0.7483848581177359
303 0.7439966260318688
304 0.7410579542105343
305 0.7480140607844117
306 0.7407830065723816
307 0.7376616702284864
308 0.7431501495795438
309 0.7422155805386096
310 0.7448275451591793
Train R2 - DI: 0.354
Val R2 - DI: 0.282
Test R2 - DI: 0.296
311 0.7326974844847102
312 0.7394077175834273
313 0.7475057225500811
314 0.7414645698335436
315 0.7370507961960249
316 0.7387765977545023
317 0.7430490717665696
318 0.7367183889112164
319 0.7413995435588249
320 0.7380148192460392
Train R2 - DI: 0.355
Val R2 - DI: 0.281
Test R2 - DI: 0.292
321 0.7415882621187463
322 0.7298452876801986
323 0.7354013930939431
324 0.7313254228202245
325 0.7342818496475083
326 0.7377782376863623
327 0.7390714830395141
328 0.7433744493778461
329 0.7235475227396976
330 0.7402983852612075
Train R2 - DI: 0.357
Val R2 - DI: 0.284
Test R2 - DI: 0.296
331 0.7403045338969076
332 0.7278709138593366
333 0.7362446102190189
334 0.7402898440437932
335 0.7365788819542068
336 0.7405405009946515
337 0.7350195447176588
338 0.7273708599869922
339 0.7326188719400796
340 0.7378469459899437
Train R2 - DI: 0.360
Val R2 - DI: 0.284
Test R2 - DI: 0.297
341 0.7341486654828526
342 0.7354157081641604
343 0.74245606836025
344 0.7351304769088718
345 0.7271886199178661
346 0.726820780000379
347 0.725698389331927
348 0.7230126870575772
349 0.7327404744736182
350 0.736378725455226
Train R2 - DI: 0.360
Val R2 - DI: 0.285
Test R2 - DI: 0.297
351 0.7367891522718587
352 0.7264427664032119
353 0.7379638400129093
354 0.7291714085472955
355 0.7309243766637686
356 0.7344033180171871
357 0.7278358694900321
358 0.7357781696063216
359 0.7301380115170633
360 0.7287683403620155
Train R2 - DI: 0.359
Val R2 - DI: 0.284
Test R2 - DI: 0.295
361 0.7361859241266832
362 0.7259837708165569
363 0.7301675411108147
364 0.7213369798916642
365 0.7402079980860474
366 0.7282966496269335
367 0.7434902848735933
368 0.728628121567456
369 0.7365898007133101
370 0.7232316305987724
Train R2 - DI: 0.361
Val R2 - DI: 0.287
Test R2 - DI: 0.300
371 0.7265288713585092
372 0.7283832001429732
373 0.7290220655848049
374 0.729192807383862
375 0.7188165006244481
376 0.7288534639556775
377 0.7248420828986766
378 0.7188221098701586
379 0.7282820775517426
380 0.7250551037463663
Train R2 - DI: 0.364
Val R2 - DI: 0.286
Test R2 - DI: 0.298
381 0.7332701474534995
382 0.7305651979207138
383 0.7257295712347953
384 0.7225455668237474
385 0.7238486137868683
386 0.7369899105000239
387 0.7180344090666823
388 0.7346559417290499
389 0.7314891696830804
390 0.7200684526060644
Train R2 - DI: 0.366
Val R2 - DI: 0.287
Test R2 - DI: 0.300
391 0.7291211924672554
392 0.7214355755023204
393 0.7315361030212867
394 0.7200440035498697
395 0.7230897145032028
396 0.7228060565114448
397 0.7247940276258735
398 0.7301793136904317
399 0.7295605266393299
400 0.7191394916999297
Train R2 - DI: 0.364
Val R2 - DI: 0.287
Test R2 - DI: 0.299
0.2874528262262851
Test R2 - DI: 0.299
Test R2 - DI: 0.300
CNN_simple
batch_size =  128 lr =  1e-06 wd =  10.0
5580 1000 1000
cuda:0
Using SGD
1 3.130128151199724
2 1.9826532283564196
3 1.5579416964643744
4 1.367955089042691
5 1.2717442811603614
6 1.2019992043895107
7 1.1602537060296663
8 1.1179181233956395
9 1.1079415399113863
10 1.0919603274287288
Train R2 - DI: 0.065
Val R2 - DI: 0.089
Test R2 - DI: 0.063
11 1.0770928429873614
12 1.0670763475920564
13 1.0387823413349822
14 1.0235166276227616
15 1.040606645700325
16 1.022304249237088
17 1.0129528554964236
18 1.0177801826521486
19 0.9845178481925773
20 0.9997901458466779
Train R2 - DI: 0.152
Val R2 - DI: 0.162
Test R2 - DI: 0.162
21 0.985640846700224
22 0.9751858630060722
23 0.960764658664717
24 0.958185462584205
25 0.9611100694184662
26 0.9561641252169045
27 0.9349179176019511
28 0.9297879592492162
29 0.9356657132025687
30 0.9433634916514051
Train R2 - DI: 0.181
Val R2 - DI: 0.191
Test R2 - DI: 0.194
31 0.9282124618902856
32 0.9434845820122723
33 0.9119886252615187
34 0.9235464817734175
35 0.9322569193378571
36 0.9265965478394621
37 0.9180082210930445
38 0.9196312004092774
39 0.9026586440728984
40 0.9208647724975394
Train R2 - DI: 0.206
Val R2 - DI: 0.213
Test R2 - DI: 0.219
41 0.9012871715330308
42 0.9067762246268625
43 0.896179290783448
44 0.9007205692243405
45 0.8894783733138901
46 0.8824556125962179
47 0.8916922800857107
48 0.8884542680983047
49 0.8865063001178072
50 0.879764975100008
Train R2 - DI: 0.231
Val R2 - DI: 0.234
Test R2 - DI: 0.246
51 0.8880590471315555
52 0.8670372459623549
53 0.8760961099337506
54 0.8779166783483225
55 0.8726550390643458
56 0.8825586028423787
57 0.867961191575587
58 0.8651539340668681
59 0.8545446393310383
60 0.8781201910801686
Train R2 - DI: 0.251
Val R2 - DI: 0.244
Test R2 - DI: 0.265
61 0.8807636811741791
62 0.8652571936234779
63 0.866373126224805
64 0.8526593380076911
65 0.8681379259273571
66 0.8622439694660966
67 0.8630765706834828
68 0.8470566180444533
69 0.840150711527862
70 0.8579801703012118
Train R2 - DI: 0.258
Val R2 - DI: 0.252
Test R2 - DI: 0.272
71 0.8569120604932094
72 0.8506447273343267
73 0.8566943754859295
74 0.8556582768330865
75 0.8479241397645738
76 0.8425938475516535
77 0.8447177701526218
78 0.8524772249242311
79 0.8468418001701328
80 0.8509221338456677
Train R2 - DI: 0.268
Val R2 - DI: 0.258
Test R2 - DI: 0.281
81 0.8289369893757673
82 0.8394699890553737
83 0.8348575567259157
84 0.8502501036531181
85 0.8335921887855803
86 0.8313543433356884
87 0.8395738118011037
88 0.8258055354104674
89 0.8274332490873166
90 0.8332181785269023
Train R2 - DI: 0.272
Val R2 - DI: 0.262
Test R2 - DI: 0.286
91 0.8445014423366943
92 0.8275261349148221
93 0.8201864306217453
94 0.8264420562320285
95 0.8330665579833437
96 0.8362882960227228
97 0.8245045091516228
98 0.8297881809614038
99 0.8165201287115774
100 0.8262143452534966
Train R2 - DI: 0.282
Val R2 - DI: 0.268
Test R2 - DI: 0.294
101 0.8204115226277314
102 0.8207972950405544
103 0.825455289673207
104 0.8215769377233307
105 0.8282151369211067
106 0.8212505834504268
107 0.8131024282892972
108 0.8140197676142484
109 0.8145651633594199
110 0.8297042700979445
Train R2 - DI: 0.288
Val R2 - DI: 0.270
Test R2 - DI: 0.299
111 0.8098798159630068
112 0.8202952310603152
113 0.8157661240587952
114 0.8161216971694782
115 0.8113066353251003
116 0.811909013367041
117 0.8011576544853949
118 0.804781592832244
119 0.804820606187253
120 0.806825132951087
Train R2 - DI: 0.292
Val R2 - DI: 0.274
Test R2 - DI: 0.301
121 0.8094114421516336
122 0.8090573273251989
123 0.8130295782533598
124 0.8120182459926947
125 0.7972089010754794
126 0.8084274316774047
127 0.8120828757149344
128 0.8127565379211125
129 0.8019919654374481
130 0.8086421569188436
Train R2 - DI: 0.286
Val R2 - DI: 0.269
Test R2 - DI: 0.296
131 0.8059717662872806
132 0.805606718473537
133 0.8072572021928739
134 0.8069474894086093
135 0.7967131668948786
136 0.792497434325543
137 0.806510122147085
138 0.7939163125116765
139 0.8026043624860839
140 0.8044915287298113
Train R2 - DI: 0.298
Val R2 - DI: 0.277
Test R2 - DI: 0.306
141 0.7948485620560185
142 0.8109494274235114
143 0.8011480706994252
144 0.7991833092063986
145 0.7991615627401618
146 0.7955168639032644
147 0.8023538771496024
148 0.8023106461357472
149 0.7884387466642592
150 0.7951145949329527
Train R2 - DI: 0.303
Val R2 - DI: 0.280
Test R2 - DI: 0.311
151 0.7983288509657733
152 0.8024472928816272
153 0.7937391196527789
154 0.7858413265170162
155 0.799228860699575
156 0.7896780895930464
157 0.8015428975491541
158 0.7848792837512109
159 0.8023374561767852
160 0.7992079193019526
Train R2 - DI: 0.299
Val R2 - DI: 0.277
Test R2 - DI: 0.308
161 0.7993602411294068
162 0.7818088637457954
163 0.7808645902568722
164 0.7913329323560107
165 0.7840867597569702
166 0.7935338629616632
167 0.790782963887765
168 0.7950204566388147
169 0.8023337923924982
170 0.7841588586462014
Train R2 - DI: 0.302
Val R2 - DI: 0.279
Test R2 - DI: 0.310
171 0.791274247759132
172 0.7765143379942918
173 0.7852657508679188
174 0.7973558764731158
175 0.791228123975911
176 0.7782447983287142
177 0.7929382649373837
178 0.7800940790911302
179 0.7865124910108505
180 0.7912222006842227
Train R2 - DI: 0.310
Val R2 - DI: 0.283
Test R2 - DI: 0.316
181 0.7887876684520407
182 0.7810036559686011
183 0.7806552098643396
184 0.7771613649142686
185 0.7808629298722872
186 0.7853102573357176
187 0.77706451586925
188 0.7778597227134157
189 0.7769870605092749
190 0.7816302559709036
Train R2 - DI: 0.312
Val R2 - DI: 0.285
Test R2 - DI: 0.317
191 0.7761084956507529
192 0.7788673567515547
193 0.7834626561424638
194 0.7772022074268711
195 0.7792913439026016
196 0.7809846610151311
197 0.7720010231472685
198 0.7769551506179208
199 0.782183555505609
200 0.7804547765348975
Train R2 - DI: 0.310
Val R2 - DI: 0.282
Test R2 - DI: 0.317
201 0.7752585062843924
202 0.7788024498143077
203 0.7779744306345567
204 0.7797318994785295
205 0.7775423738264269
206 0.7765815073443997
207 0.7738050763752298
208 0.7689975961562125
209 0.7755721360124568
210 0.7761855999628703
Train R2 - DI: 0.318
Val R2 - DI: 0.285
Test R2 - DI: 0.321
211 0.7738367665198541
212 0.7738087621213715
213 0.7708098529914801
214 0.774458458688524
215 0.7749414082496396
216 0.7747944012337689
217 0.7733556178308303
218 0.7704739865009076
219 0.7691145987066317
220 0.7669658048605833
Train R2 - DI: 0.315
Val R2 - DI: 0.286
Test R2 - DI: 0.318
221 0.76448528172722
222 0.7773758302880017
223 0.7735451738466926
224 0.7722123070857003
225 0.7654972490016705
226 0.7719623694710407
227 0.7718811764084738
228 0.7732064386849762
229 0.7724941227171156
230 0.7735910314812883
Train R2 - DI: 0.318
Val R2 - DI: 0.287
Test R2 - DI: 0.322
231 0.777441282511612
232 0.7694247402170653
233 0.7620231207980904
234 0.7707470888305309
235 0.7652533841816755
236 0.7709041515558851
237 0.7688767612194075
238 0.7602364516600059
239 0.7667532987492058
240 0.7677191565540956
Train R2 - DI: 0.320
Val R2 - DI: 0.288
Test R2 - DI: 0.322
241 0.7632266259107966
242 0.7609324568488692
243 0.7702839784297465
244 0.7713393090446363
245 0.7660754621242537
246 0.7683919324669787
247 0.76045635639553
248 0.7771852634713641
249 0.7692637852870435
250 0.7744047199526141
Train R2 - DI: 0.318
Val R2 - DI: 0.286
Test R2 - DI: 0.321
251 0.7588437630284217
252 0.76939210998542
253 0.7640523052984668
254 0.7649146628208913
255 0.7636361983941875
256 0.761107793161946
257 0.7579489534901035
258 0.7664509438699292
259 0.7629547408404743
260 0.7583830718925777
Train R2 - DI: 0.323
Val R2 - DI: 0.290
Test R2 - DI: 0.324
261 0.75652202119964
262 0.7666696634771148
263 0.7740781640066469
264 0.7681431750670129
265 0.7593442822015414
266 0.7686661940748973
267 0.7609205991563831
268 0.7604982970435987
269 0.7604898076758162
270 0.7561685143405819
Train R2 - DI: 0.325
Val R2 - DI: 0.290
Test R2 - DI: 0.326
271 0.7691821051327559
272 0.7563481083907534
273 0.7559141675203932
274 0.7571437916020766
275 0.7608376905055029
276 0.7627651921737151
277 0.7567839969870864
278 0.7636910712419872
279 0.7601103068679892
280 0.7609997400246213
Train R2 - DI: 0.327
Val R2 - DI: 0.291
Test R2 - DI: 0.327
281 0.7576862742823939
282 0.7544519900848361
283 0.762096591149607
284 0.7564925207032098
285 0.7607859499992863
286 0.752373023870598
287 0.7607946924411267
288 0.7614457931569828
289 0.7640490392202972
290 0.7596270515500003
Train R2 - DI: 0.325
Val R2 - DI: 0.290
Test R2 - DI: 0.324
291 0.7597851728025731
292 0.75338036620916
293 0.7589179750411741
294 0.7575423535907567
295 0.7542365975277399
296 0.7517305983010159
297 0.7564697338688758
298 0.754058008253788
299 0.7507440684089524
300 0.7521851134129323
Train R2 - DI: 0.325
Val R2 - DI: 0.290
Test R2 - DI: 0.324
301 0.76358066788711
302 0.7625098936446678
303 0.7553732407990322
304 0.7617371713816051
305 0.7602828267654638
306 0.7503636511850528
307 0.7626734273408049
308 0.7575075828046355
309 0.7579810979545757
310 0.7593381479649561
Train R2 - DI: 0.330
Val R2 - DI: 0.292
Test R2 - DI: 0.329
311 0.757817106862222
312 0.7587404702299385
313 0.7559830545524543
314 0.7557476205637805
315 0.7517378352876205
316 0.7494331495308961
317 0.7508070871821441
318 0.7603972889616498
319 0.7567226214220875
320 0.7583598059565363
Train R2 - DI: 0.328
Val R2 - DI: 0.292
Test R2 - DI: 0.327
321 0.7526256045132982
322 0.7567044518327201
323 0.7591341875360004
324 0.7515016777541048
325 0.7564428756741213
326 0.7538346477306872
327 0.7540307458156326
328 0.7392769390964167
329 0.7513341434113013
330 0.7539902910109489
Train R2 - DI: 0.327
Val R2 - DI: 0.290
Test R2 - DI: 0.326
331 0.7620645887535533
332 0.7522584954043016
333 0.746395493066439
334 0.7513970957862006
335 0.7542899992303609
336 0.7419399688320775
337 0.7517053971153861
338 0.748956437350174
339 0.7504135404436392
340 0.7534221514151515
Train R2 - DI: 0.333
Val R2 - DI: 0.294
Test R2 - DI: 0.330
341 0.749958462569876
342 0.7525629477688915
343 0.7547483259204468
344 0.7475992794959776
345 0.7462512591406436
346 0.7509912143898694
347 0.755591662382994
348 0.7569969149046046
349 0.7576785607577224
350 0.7561728393305159
Train R2 - DI: 0.329
Val R2 - DI: 0.291
Test R2 - DI: 0.327
351 0.7665315210178334
352 0.7591313610367451
353 0.7594908654476152
354 0.7566155403318371
355 0.7443913299123018
356 0.756890247842317
357 0.7528302876752765
358 0.7459009341014329
359 0.747920084768726
360 0.7505489401919867
Train R2 - DI: 0.329
Val R2 - DI: 0.292
Test R2 - DI: 0.326
361 0.7524318945023322
362 0.7397518081904312
363 0.7518599768266029
364 0.757334118504678
365 0.7396419648628508
366 0.7547791410090675
367 0.7561474222863447
368 0.7477308778779909
369 0.7562276036508622
370 0.7506513192662202
Train R2 - DI: 0.334
Val R2 - DI: 0.294
Test R2 - DI: 0.331
371 0.7512151699339618
372 0.7536063953539804
373 0.7492727148917413
374 0.74554395244113
375 0.7479016639425763
376 0.7424847224279971
377 0.7460223399610075
378 0.7499666772862916
379 0.7533537260520415
380 0.7343430458858449
Train R2 - DI: 0.332
Val R2 - DI: 0.293
Test R2 - DI: 0.329
381 0.7473575886005142
382 0.7466911318481609
383 0.7428355328071075
384 0.7452703533634063
385 0.7408825991828809
386 0.747370366340897
387 0.7424863938789641
388 0.7459415070899499
389 0.7500478436015413
390 0.7525713031864508
Train R2 - DI: 0.334
Val R2 - DI: 0.294
Test R2 - DI: 0.329
391 0.7420370323683626
392 0.7462606604808547
393 0.7499183175384357
394 0.7386364025881641
395 0.7482073767210847
396 0.7440994663477799
397 0.7509457041713072
398 0.755883775517932
399 0.7460287099670766
400 0.7537848698622864
Train R2 - DI: 0.331
Val R2 - DI: 0.292
Test R2 - DI: 0.327
0.2942474991412459
Test R2 - DI: 0.327
Test R2 - DI: 0.331

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 14772625: <testjob> in cluster <dcc> Exited

Job <testjob> was submitted from host <n-62-30-8> by user <s174503> in cluster <dcc> at Tue Nov 15 21:21:58 2022
Job was executed on host(s) <n-62-20-10>, in queue <gpuv100>, as user <s174503> in cluster <dcc> at Tue Nov 15 21:22:00 2022
</zhome/fd/6/127382> was used as the home directory.
</zhome/fd/6/127382/Desktop/MasterThesis/Master-thesis> was used as the working directory.
Started at Tue Nov 15 21:22:00 2022
Terminated at Wed Nov 16 09:21:26 2022
Results reported at Wed Nov 16 09:21:26 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J testjob
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 12:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -o outputs/gpu_%J.out
#BSUB -e outputs/errors/gpu_%J.err

nvidia-smi
module load cuda/11.6

/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery

source $HOME/miniconda3/bin/activate
source venv_1/bin/activate

python3 main.py CNN_simple 128 1e-6 5 400 shuffle_sgd_2wd5 99 SGD
python3 main.py CNN_simple 128 1e-6 10 400 shuffle_sgd_2wd10 99 SGD
python3 main.py CNN_simple 128 1e-6 15 400 shuffle_sgd_2wd15 99 SGD
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   30482.00 sec.
    Max Memory :                                 2253 MB
    Average Memory :                             2205.23 MB
    Total Requested Memory :                     5120.00 MB
    Delta Memory :                               2867.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   43251 sec.
    Turnaround time :                            43168 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/errors/gpu_14772625.err> for stderr output of this job.

