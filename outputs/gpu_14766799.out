Tue Nov 15 13:48:53 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:AF:00.0 Off |                    0 |
| N/A   30C    P0    24W / 250W |      0MiB / 16384MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-PCIE-16GB"
  CUDA Driver Version / Runtime Version          11.8 / 11.6
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 16161 MBytes (16945709056 bytes)
  (080) Multiprocessors, (064) CUDA Cores/MP:    5120 CUDA Cores
  GPU Max Clock rate:                            1380 MHz (1.38 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 7 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 175 / 0
  Compute Mode:
     < Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.8, CUDA Runtime Version = 11.6, NumDevs = 1
Result = PASS
CNN_simple
batch_size =  128 lr =  1e-06 wd =  1.0
5580 1000 1000
cuda:0
Using SGD
1 2.812213120751056
2 1.972575764331339
3 1.6544897484522993
4 1.45460776282895
5 1.3453658497888983
6 1.2933578754411377
7 1.2259844051894322
8 1.1808642983863857
9 1.1341902558521557
10 1.106400960406095
Train R2 - DI: 0.025
Val R2 - DI: 0.018
Test R2 - DI: -0.002
11 1.0929460968167979
12 1.0573338175332674
13 1.0557237709722211
14 1.0357807048332734
15 1.035435627865535
16 1.0131401475612407
17 1.0045180704431294
18 1.0123304786220673
19 0.9831909878706847
20 0.9800404812700005
Train R2 - DI: 0.137
Val R2 - DI: 0.141
Test R2 - DI: 0.119
21 0.9776900652061654
22 0.9840262003269674
23 0.9896367182441083
24 0.9633105606161138
25 0.9592889140156435
26 0.9518883293247564
27 0.951170924102961
28 0.9409228382144778
29 0.9273511825069305
30 0.9395579824738178
Train R2 - DI: 0.182
Val R2 - DI: 0.185
Test R2 - DI: 0.165
31 0.9416651260895541
32 0.9165956962493158
33 0.9312081163074808
34 0.8937430866302982
35 0.9127628316161454
36 0.9057204844276537
37 0.9119300365875271
38 0.9089875431470974
39 0.9093138474290089
40 0.9018871650900891
Train R2 - DI: 0.208
Val R2 - DI: 0.204
Test R2 - DI: 0.189
41 0.8868593770116033
42 0.9018524505758798
43 0.9009990582329398
44 0.9001271483718708
45 0.8830833369685758
46 0.8864064722078249
47 0.8640017165932604
48 0.874749737102071
49 0.870108223986882
50 0.8707023353132296
Train R2 - DI: 0.227
Val R2 - DI: 0.215
Test R2 - DI: 0.205
51 0.8745841026306153
52 0.8651380800431775
53 0.8836394567216169
54 0.8687454729524564
55 0.8718736392195506
56 0.8690932608847123
57 0.8593175762015859
58 0.8603371103177361
59 0.8566922058768597
60 0.8652995082639878
Train R2 - DI: 0.244
Val R2 - DI: 0.229
Test R2 - DI: 0.219
61 0.8721809427798008
62 0.8464171724934731
63 0.8543123876322127
64 0.8607848808756866
65 0.8523945228600588
66 0.8529823999678362
67 0.8429716016229336
68 0.8501461283707704
69 0.846237862622866
70 0.8517035868005514
Train R2 - DI: 0.260
Val R2 - DI: 0.249
Test R2 - DI: 0.234
71 0.8252361407843969
72 0.834505895303569
73 0.8343182044644509
74 0.8430155051651821
75 0.8347145071166391
76 0.8359450136034292
77 0.8310555333732277
78 0.829296244387131
79 0.8309111032861962
80 0.8268678698061188
Train R2 - DI: 0.273
Val R2 - DI: 0.257
Test R2 - DI: 0.244
81 0.8312838605227864
82 0.8188192935400112
83 0.8325469353293006
84 0.8315823412283347
85 0.8281451323980926
86 0.8210117019632811
87 0.8091507137889931
88 0.8130788144244943
89 0.8068831526677668
90 0.8168763122250957
Train R2 - DI: 0.279
Val R2 - DI: 0.257
Test R2 - DI: 0.248
91 0.816211836953317
92 0.8206757750989716
93 0.8209337645106846
94 0.8078197263902234
95 0.8190454902614744
96 0.8119068595243611
97 0.8072425707266749
98 0.8182285366092531
99 0.8169846936366036
100 0.8284238396152374
Train R2 - DI: 0.286
Val R2 - DI: 0.262
Test R2 - DI: 0.253
0.2618094819800951
Test R2 - DI: 0.253
Test R2 - DI: 0.253
CNN_simple
batch_size =  128 lr =  1e-06 wd =  1.0
5580 1000 1000
cuda:0
Using SGD
1 3.206356139849591
2 2.20764448976004
3 1.7676166396841781
4 1.5335792249248874
5 1.3934633976242448
6 1.280301761199924
7 1.24082625651445
8 1.1647718972202699
9 1.1502331706358113
10 1.1125457989272252
Train R2 - DI: 0.026
Val R2 - DI: -0.072
Test R2 - DI: -0.035
11 1.0873045414579385
12 1.0889605502501183
13 1.0574982523918153
14 1.0517190190626302
15 1.0336169030076714
16 1.0283617796436433
17 1.0209222151814397
18 1.0074678314202148
19 0.9982356113772238
20 0.9992666197934031
Train R2 - DI: 0.137
Val R2 - DI: 0.055
Test R2 - DI: 0.083
21 0.9995873442260168
22 0.9855274667022049
23 0.9722106432402006
24 0.9821655384101321
25 0.9722164521507892
26 0.9798453259211715
27 0.9510833951307454
28 0.9413924610315685
29 0.9544817595926237
30 0.945547180791055
Train R2 - DI: 0.183
Val R2 - DI: 0.108
Test R2 - DI: 0.128
31 0.9361728434067046
32 0.934976691926252
33 0.9326198521053491
34 0.923833168792041
35 0.9289813237378247
36 0.9390267992105108
37 0.9143170453314285
38 0.9163773328172691
39 0.9115377211228921
40 0.9084399228454918
Train R2 - DI: 0.211
Val R2 - DI: 0.140
Test R2 - DI: 0.157
41 0.9158086194786974
42 0.9104260294668136
43 0.9004879288348673
44 0.8980061129857135
45 0.8940671652021374
46 0.8918226451429415
47 0.8901927843743328
48 0.8910393367104206
49 0.8928062197128077
50 0.882262828529522
Train R2 - DI: 0.231
Val R2 - DI: 0.159
Test R2 - DI: 0.174
51 0.8870905590313737
52 0.8721955840305615
53 0.8860140209129634
54 0.8816786917307043
55 0.8839223798885141
56 0.8644639305743692
57 0.8735643117658554
58 0.8654887498920536
59 0.8793296652455483
60 0.8674105698917074
Train R2 - DI: 0.250
Val R2 - DI: 0.176
Test R2 - DI: 0.191
61 0.8570213996381315
62 0.8749489478312941
63 0.8561439050568475
64 0.8606049322740151
65 0.8493971565718292
66 0.8589502332031086
67 0.8488496500531405
68 0.85741889510958
69 0.8452577997706697
70 0.8716117340604037
Train R2 - DI: 0.257
Val R2 - DI: 0.185
Test R2 - DI: 0.199
71 0.8569223807276791
72 0.8477007346768533
73 0.860576861733604
74 0.8476085747869211
75 0.8486450334603641
76 0.8459924030474865
77 0.8547564251021245
78 0.8400564365489509
79 0.8347083146854114
80 0.8314261022007167
Train R2 - DI: 0.270
Val R2 - DI: 0.198
Test R2 - DI: 0.209
81 0.8385235899238176
82 0.8337571270576942
83 0.8410799283707868
84 0.8327687412179926
85 0.839944259667482
86 0.8214150477053871
87 0.8309726741578843
88 0.8366645488260468
89 0.822958442045369
90 0.8167069844447584
Train R2 - DI: 0.284
Val R2 - DI: 0.206
Test R2 - DI: 0.221
91 0.8228332246930796
92 0.816665901419937
93 0.8309723800228488
94 0.8160108362902022
95 0.8049730096666616
96 0.8192201311015741
97 0.8120363312382852
98 0.8181340331245067
99 0.8103177063354027
100 0.8208932044685527
Train R2 - DI: 0.292
Val R2 - DI: 0.215
Test R2 - DI: 0.228
101 0.8168606444926245
102 0.8126022095321327
103 0.812880073525145
104 0.8216522162105875
105 0.8124808484935419
106 0.8040562210544463
107 0.8101731880591334
108 0.8066443503116622
109 0.8139650314512219
110 0.8126291287842617
Train R2 - DI: 0.299
Val R2 - DI: 0.220
Test R2 - DI: 0.234
111 0.8109040498306247
112 0.807934855560248
113 0.8095380400671327
114 0.8047660511454374
115 0.8056861888123242
116 0.8020315188660844
117 0.7983153121018495
118 0.7960968090641883
119 0.7910842646407398
120 0.7928919486247511
Train R2 - DI: 0.305
Val R2 - DI: 0.225
Test R2 - DI: 0.237
121 0.8059934147797178
122 0.7986566115023842
123 0.798968163100622
124 0.8002910258949444
125 0.8086500875411495
126 0.7975591739446032
127 0.8010229285899884
128 0.8063598252111865
129 0.7896202549712205
130 0.800762342124857
Train R2 - DI: 0.311
Val R2 - DI: 0.228
Test R2 - DI: 0.241
131 0.8024423521906672
132 0.8082888298137214
133 0.7914710860098562
134 0.7957535402321901
135 0.7950137170839481
136 0.7882830634339308
137 0.7837209361001155
138 0.7839807475766828
139 0.7890080176801237
140 0.7833374017455672
Train R2 - DI: 0.314
Val R2 - DI: 0.232
Test R2 - DI: 0.245
141 0.7957335093969939
142 0.7962744241546986
143 0.7898643439388617
144 0.785850123778039
145 0.7899887773725721
146 0.7895558635393779
147 0.792188628044607
148 0.7835949764029527
149 0.7824889642363381
150 0.7900185255166877
Train R2 - DI: 0.319
Val R2 - DI: 0.233
Test R2 - DI: 0.247
151 0.788795049387067
152 0.7852634410704336
153 0.776495632903123
154 0.7930058988619022
155 0.7778324428852313
156 0.7807932943853426
157 0.7757968744923992
158 0.7824288263970378
159 0.7782394338252296
160 0.7871253528902608
Train R2 - DI: 0.323
Val R2 - DI: 0.237
Test R2 - DI: 0.251
161 0.7776878096724069
162 0.7836475715842298
163 0.7786580211372786
164 0.7701379247036458
165 0.7747624306268589
166 0.7874939022098391
167 0.7771142837394522
168 0.7734914666435625
169 0.7726318809293932
170 0.7770641876805213
Train R2 - DI: 0.323
Val R2 - DI: 0.240
Test R2 - DI: 0.250
171 0.7799089517644656
172 0.7672773809843166
173 0.76887791716497
174 0.7669054266799735
175 0.7724943469074892
176 0.773919926578426
177 0.756851153988992
178 0.7737319765552397
179 0.7629739263578982
180 0.7671022972752971
Train R2 - DI: 0.330
Val R2 - DI: 0.243
Test R2 - DI: 0.255
181 0.7694403843213153
182 0.7745551572905647
183 0.7620712323428055
184 0.7713708633590343
185 0.7761200116953969
186 0.7759728074073792
187 0.7778038720930777
188 0.7702997260196235
189 0.7660216112717932
190 0.7773964074350173
Train R2 - DI: 0.334
Val R2 - DI: 0.245
Test R2 - DI: 0.257
191 0.7694880547489317
192 0.775518317290959
193 0.7749692134959724
194 0.7661050821290648
195 0.7675717044902104
196 0.7673309056989608
197 0.7637788972546977
198 0.7633667142160477
199 0.7564655959819807
200 0.7615830491947871
Train R2 - DI: 0.337
Val R2 - DI: 0.247
Test R2 - DI: 0.259
201 0.7532786725669779
202 0.7656921651628282
203 0.7644349963007008
204 0.7554739046694985
205 0.7753908328685282
206 0.7515325596255641
207 0.7543537077083382
208 0.7555671224884662
209 0.7571518015263329
210 0.7644792702890212
Train R2 - DI: 0.336
Val R2 - DI: 0.247
Test R2 - DI: 0.259
211 0.7642868782029785
212 0.7590441834114786
213 0.7581950223146801
214 0.7519715343324942
215 0.7628338160907923
216 0.7584538323477605
217 0.7583510830838193
218 0.7576247373789442
219 0.7609023435141451
220 0.7594102642228526
Train R2 - DI: 0.339
Val R2 - DI: 0.252
Test R2 - DI: 0.260
221 0.7574216404696092
222 0.7575578910475563
223 0.7481553624180483
224 0.7449508441391811
225 0.7499854975703797
226 0.7578186579075338
227 0.7539878358550396
228 0.7541296561986315
229 0.7553330189438276
230 0.7608749332393797
Train R2 - DI: 0.344
Val R2 - DI: 0.253
Test R2 - DI: 0.264
231 0.7617143623290523
232 0.752268710016777
233 0.7506011402735147
234 0.7477834873729282
235 0.7456391595597763
236 0.7555214568278268
237 0.7495509298044294
238 0.7391666598644735
239 0.7554406213504012
240 0.7514521640261441
Train R2 - DI: 0.347
Val R2 - DI: 0.254
Test R2 - DI: 0.264
241 0.7366464360213194
242 0.7537457260179691
243 0.7369985603089828
244 0.7396429573335955
245 0.7464898427327474
246 0.7571586702886876
247 0.750136400764561
248 0.7559777615745435
249 0.735069391462538
250 0.7495956574716875
Train R2 - DI: 0.347
Val R2 - DI: 0.254
Test R2 - DI: 0.265
251 0.7470231282668301
252 0.7509750999430175
253 0.7453757280944496
254 0.7431630766519937
255 0.745585143865223
256 0.737879701925435
257 0.7472732384572319
258 0.7519381383841183
259 0.7485030421646692
260 0.7337898996568495
Train R2 - DI: 0.352
Val R2 - DI: 0.257
Test R2 - DI: 0.267
261 0.7385581381432045
262 0.7450995206405612
263 0.7559184233774848
264 0.74012395190509
265 0.7465634682699771
266 0.743042841948916
267 0.7453059750645818
268 0.7441676823041772
269 0.7440118677299937
270 0.7371179958398197
Train R2 - DI: 0.355
Val R2 - DI: 0.257
Test R2 - DI: 0.268
271 0.7425032872452958
272 0.7473295547201642
273 0.7411508882344837
274 0.746407729536829
275 0.7337321072923667
276 0.7311345357621443
277 0.7437880473324903
278 0.7380540680714406
279 0.7423976745656742
280 0.7381582039658742
Train R2 - DI: 0.353
Val R2 - DI: 0.260
Test R2 - DI: 0.267
281 0.7360368989915403
282 0.7400066714987532
283 0.7329419603484506
284 0.7389164914794293
285 0.7407130976090722
286 0.7390260020464552
287 0.7389180628202294
288 0.7301790549763642
289 0.7392423470815023
290 0.7399206616545236
Train R2 - DI: 0.360
Val R2 - DI: 0.260
Test R2 - DI: 0.270
291 0.7440061670904946
292 0.7259541291917097
293 0.7292474836858798
294 0.7391244100840716
295 0.7352089200823111
296 0.7418517550259935
297 0.7395527588423862
298 0.7318002390605147
299 0.7343835814452085
300 0.7370119237130688
Train R2 - DI: 0.361
Val R2 - DI: 0.262
Test R2 - DI: 0.271
0.2619784770850744
Test R2 - DI: 0.271
Test R2 - DI: 0.271
CNN_simple
batch_size =  128 lr =  1e-06 wd =  1.0
5580 1000 1000
cuda:0
Using SGD
1 2.49104372386864
2 1.7074961232455401
3 1.4675518238416283
4 1.3219521970304537
5 1.2735146443049112
6 1.212201605304595
7 1.1743016579672427
8 1.1281499029487692
9 1.114913734398435
10 1.0982702459485727
Train R2 - DI: 0.030
Val R2 - DI: 0.024
Test R2 - DI: -0.001
11 1.090745886594164
12 1.073379778434726
13 1.043992186532653
14 1.027109162012736
15 1.0303911548361555
16 1.0209691610387577
17 1.0204441005611078
18 1.00335305848002
19 1.004173802474921
20 0.9906094809159584
Train R2 - DI: 0.135
Val R2 - DI: 0.112
Test R2 - DI: 0.096
21 0.9859104513694735
22 0.9983325125923294
23 0.9568482063577166
24 0.9709075082587512
25 0.9470308063705335
26 0.9398944976081985
27 0.9496955314417467
28 0.9418768198259415
29 0.9344430011233121
30 0.9321033943938525
Train R2 - DI: 0.179
Val R2 - DI: 0.158
Test R2 - DI: 0.133
31 0.92737510802498
32 0.9113821183481524
33 0.9141272313278636
34 0.9105417313114289
35 0.9003243921050889
36 0.9085902757969381
37 0.9072181132531936
38 0.9042192227524242
39 0.9025104399650328
40 0.8840196905597564
Train R2 - DI: 0.217
Val R2 - DI: 0.191
Test R2 - DI: 0.162
41 0.8959520318174875
42 0.9008196551312683
43 0.8961452604194696
44 0.8664746448985138
45 0.8898231192301679
46 0.886609603427217
47 0.8795287236517902
48 0.8762245364513875
49 0.8692798065455584
50 0.8745054632104853
Train R2 - DI: 0.236
Val R2 - DI: 0.215
Test R2 - DI: 0.180
51 0.8724588897493151
52 0.8693906314484108
53 0.8688153773225764
54 0.8712142563635303
55 0.8659184772908474
56 0.8490527957571022
57 0.8543763313669458
58 0.8510268877911311
59 0.850643137663496
60 0.8501388061003873
Train R2 - DI: 0.255
Val R2 - DI: 0.231
Test R2 - DI: 0.192
61 0.8468729557529573
62 0.8392353777389799
63 0.8372717442051056
64 0.8423225203295335
65 0.8361322645218142
66 0.8353885046042849
67 0.8308456050025093
68 0.826505529666887
69 0.8233732587974986
70 0.8352283479065024
Train R2 - DI: 0.270
Val R2 - DI: 0.245
Test R2 - DI: 0.205
71 0.8325729577772079
72 0.8328719949636836
73 0.8368258037020229
74 0.8385150199722645
75 0.8378326276724484
76 0.8310344888745242
77 0.8277481998594004
78 0.8178016977070908
79 0.8168481255090365
80 0.8243482896504009
Train R2 - DI: 0.281
Val R2 - DI: 0.255
Test R2 - DI: 0.213
81 0.8290129861096754
82 0.8276951800537793
83 0.8300300202062053
84 0.8217400675606129
85 0.8108090086222549
86 0.8216807675617998
87 0.8166184971836733
88 0.8134250795542126
89 0.8079338339921821
90 0.805961586796682
Train R2 - DI: 0.291
Val R2 - DI: 0.266
Test R2 - DI: 0.219
91 0.8111499187766865
92 0.8039688997371223
93 0.8070140776027488
94 0.8093817541676183
95 0.8056273606942973
96 0.8092352101025189
97 0.7958312290970997
98 0.8193122204486615
99 0.8077561202015073
100 0.8039794919311359
Train R2 - DI: 0.294
Val R2 - DI: 0.267
Test R2 - DI: 0.224
101 0.8007386364389919
102 0.8032704836578779
103 0.8110666674097806
104 0.8027868229001226
105 0.7910238384773227
106 0.8000859193477152
107 0.802131713803951
108 0.8036555658104599
109 0.7967239370055523
110 0.7948757721104502
Train R2 - DI: 0.304
Val R2 - DI: 0.279
Test R2 - DI: 0.230
111 0.7950506556845908
112 0.7930332067192242
113 0.7829096130572767
114 0.7862510844370798
115 0.790463944917084
116 0.7880882815220878
117 0.7886347089617056
118 0.7896114319456093
119 0.7801448124711231
120 0.7853162812930281
Train R2 - DI: 0.310
Val R2 - DI: 0.284
Test R2 - DI: 0.235
121 0.7826582835993886
122 0.7831786171509801
123 0.7835833249553558
124 0.7946870418005092
125 0.7853994147324648
126 0.7863316735059129
127 0.7741923061322995
128 0.7770412458313836
129 0.7832939365004126
130 0.786086239481485
Train R2 - DI: 0.316
Val R2 - DI: 0.289
Test R2 - DI: 0.238
131 0.7746964727251333
132 0.7720844596090283
133 0.7773275421939015
134 0.7811353689026235
135 0.7756316721652998
136 0.78018114630894
137 0.7672945726302363
138 0.7690757271209498
139 0.7656881843416494
140 0.77596602542426
Train R2 - DI: 0.320
Val R2 - DI: 0.292
Test R2 - DI: 0.242
141 0.7809232223418451
142 0.7695505394730516
143 0.7611686689879305
144 0.7714691710728471
145 0.7756120480944179
146 0.7725524207597138
147 0.7764485290828145
148 0.7751037354110389
149 0.7697889365175719
150 0.7612638867456853
Train R2 - DI: 0.324
Val R2 - DI: 0.295
Test R2 - DI: 0.245
151 0.7694347694355954
152 0.7754045012603952
153 0.7721485265266939
154 0.7731466269407649
155 0.7755891325225966
156 0.7695323808218844
157 0.7659228230035433
158 0.7550957857494286
159 0.7710722274677728
160 0.7591156711287823
Train R2 - DI: 0.326
Val R2 - DI: 0.299
Test R2 - DI: 0.247
161 0.769070938026606
162 0.7617670668496026
163 0.7526962993392807
164 0.7597976841806938
165 0.7593576274892335
166 0.7542586215080753
167 0.7597034216354398
168 0.7546502046260355
169 0.7722468562023614
170 0.761618504216594
Train R2 - DI: 0.332
Val R2 - DI: 0.303
Test R2 - DI: 0.248
171 0.7546194935357698
172 0.7597264827793218
173 0.7558339564603717
174 0.7592225091859004
175 0.7604377047989959
176 0.7682871912115363
177 0.7536067946410093
178 0.7554929468366834
179 0.7615946904305488
180 0.764263243786323
Train R2 - DI: 0.334
Val R2 - DI: 0.306
Test R2 - DI: 0.249
181 0.755146366122803
182 0.7626098334148366
183 0.7590969730021706
184 0.7531541021494028
185 0.7453625311988229
186 0.7551506065553234
187 0.7554733232785297
188 0.7484448776877481
189 0.7492416958227807
190 0.7540387228825614
Train R2 - DI: 0.337
Val R2 - DI: 0.307
Test R2 - DI: 0.252
191 0.7507662836368794
192 0.7582067036286905
193 0.749657126139569
194 0.7644096867157995
195 0.7472252354399705
196 0.7524238671453196
197 0.7475293341076075
198 0.7413448990032238
199 0.7405932067542947
200 0.7432459100600212
Train R2 - DI: 0.339
Val R2 - DI: 0.311
Test R2 - DI: 0.253
201 0.7460238614817247
202 0.7437293486783154
203 0.7453785122936345
204 0.7386257693759002
205 0.7478076685714038
206 0.7422635481349029
207 0.7370330582382858
208 0.7515009003728094
209 0.7412047879670256
210 0.7482025909167465
Train R2 - DI: 0.345
Val R2 - DI: 0.315
Test R2 - DI: 0.252
211 0.7420379827954009
212 0.7355987839801337
213 0.7429386765298878
214 0.7410427342179001
215 0.7382104328029044
216 0.7376066342049602
217 0.7518065623912332
218 0.7432027998790947
219 0.7387518081613766
220 0.7297563590883781
Train R2 - DI: 0.348
Val R2 - DI: 0.315
Test R2 - DI: 0.256
221 0.7407937594639358
222 0.7383575181807241
223 0.7425635845430436
224 0.735348304198207
225 0.7393318228396891
226 0.7409337407371904
227 0.7475602186708895
228 0.737168976611134
229 0.7415973811166688
230 0.7380657519063641
Train R2 - DI: 0.346
Val R2 - DI: 0.313
Test R2 - DI: 0.257
231 0.7362869684414197
232 0.7324138309793233
233 0.7296639500553035
234 0.7268661379814148
235 0.7310328182781042
236 0.7373410750033608
237 0.7382151457143941
238 0.731582193178088
239 0.739971894260803
240 0.728963762115834
Train R2 - DI: 0.351
Val R2 - DI: 0.317
Test R2 - DI: 0.258
241 0.7317869415419931
242 0.7270354025252831
243 0.7379989707769031
244 0.7280211278187332
245 0.7335339306075941
246 0.7291729698044425
247 0.7337148254062967
248 0.7282788591572888
249 0.7306646597000861
250 0.7283186484408635
Train R2 - DI: 0.354
Val R2 - DI: 0.319
Test R2 - DI: 0.258
251 0.7341925412523277
252 0.7307006193745521
253 0.7251455816744049
254 0.7246044549463471
255 0.7320728498975009
256 0.7318824522384179
257 0.718961106192681
258 0.7255405329461594
259 0.7273558656801887
260 0.7280124262242335
Train R2 - DI: 0.355
Val R2 - DI: 0.319
Test R2 - DI: 0.263
261 0.7265361784820489
262 0.7227715930203811
263 0.7328768607536097
264 0.7276462642949969
265 0.7245907184470939
266 0.7184789758856579
267 0.7159443214375486
268 0.7220637985027819
269 0.7187697569101942
270 0.7383309822355975
Train R2 - DI: 0.358
Val R2 - DI: 0.322
Test R2 - DI: 0.262
271 0.7264195060644526
272 0.7240896990649589
273 0.7282374177782339
274 0.7370321465649485
275 0.7204071316240509
276 0.7186032016217495
277 0.7257105262048783
278 0.7253983462583207
279 0.7199699495001078
280 0.7216491355263631
Train R2 - DI: 0.361
Val R2 - DI: 0.325
Test R2 - DI: 0.262
281 0.7178748759317569
282 0.7165029735120821
283 0.7111913638730203
284 0.7219148749091719
285 0.7217995696597629
286 0.7260797818501791
287 0.7253449304556762
288 0.7209113735451921
289 0.7182205254886312
290 0.7297182135257242
Train R2 - DI: 0.359
Val R2 - DI: 0.321
Test R2 - DI: 0.262
291 0.7247793847514737
292 0.7200888103908962
293 0.7235517517212898
294 0.7201069434911119
295 0.7239303207312007
296 0.7156011154574733
297 0.7150855289565192
298 0.7152489153715017
299 0.7144019521265474
300 0.7133270969527596
Train R2 - DI: 0.365
Val R2 - DI: 0.326
Test R2 - DI: 0.264
301 0.7242012678081416
302 0.7143111480606927
303 0.7209392060088428
304 0.7054767999597775
305 0.7230257708539245
306 0.7174757525912322
307 0.7065723471316813
308 0.7192562346817345
309 0.7047659988898958
310 0.7133476014205632
Train R2 - DI: 0.369
Val R2 - DI: 0.329
Test R2 - DI: 0.263
311 0.717598148870639
312 0.7122761105551088
313 0.7185928988200362
314 0.7160426430377481
315 0.7074253286084821
316 0.720414211758576
317 0.7166423283170201
318 0.7179298085123834
319 0.7100274426535467
320 0.7192754373755507
Train R2 - DI: 0.369
Val R2 - DI: 0.330
Test R2 - DI: 0.262
321 0.7093328439206633
322 0.7025470410196585
323 0.7154018238026608
324 0.7220670256136139
325 0.7118265751442174
326 0.7094025246558651
327 0.713907061170079
328 0.7154604839594988
329 0.7084384483248529
330 0.7112727695468506
Train R2 - DI: 0.370
Val R2 - DI: 0.329
Test R2 - DI: 0.266
331 0.7054566748680607
332 0.7033824632244725
333 0.7127455710510199
334 0.7080722032909325
335 0.7018573234158177
336 0.7137777182363695
337 0.7106853323170789
338 0.7080779304641122
339 0.7132590857030671
340 0.7145902579830539
Train R2 - DI: 0.369
Val R2 - DI: 0.327
Test R2 - DI: 0.266
341 0.7144200598894481
342 0.7053129928086393
343 0.7073016230350754
344 0.7113554013245422
345 0.7079989453797699
346 0.7087773920814624
347 0.71116754260969
348 0.7106319824854533
349 0.7048910945119824
350 0.6990297943033198
Train R2 - DI: 0.375
Val R2 - DI: 0.332
Test R2 - DI: 0.266
351 0.6957373711370652
352 0.7051902292022568
353 0.704556534367223
354 0.7030261218761458
355 0.7039868485970309
356 0.7035487655670413
357 0.7021744417887862
358 0.7100037074430869
359 0.7010636124986902
360 0.7047619915350364
Train R2 - DI: 0.368
Val R2 - DI: 0.324
Test R2 - DI: 0.264
361 0.7126088703405046
362 0.7044419061753058
363 0.7035531661843741
364 0.7073255937586549
365 0.703631588079596
366 0.7010668494368112
367 0.699100252547999
368 0.6992686345158512
369 0.692632373216759
370 0.7039281409273865
Train R2 - DI: 0.377
Val R2 - DI: 0.333
Test R2 - DI: 0.268
371 0.7092169347629752
372 0.7012933503769632
373 0.7004946877879481
374 0.7003190764816859
375 0.6942617149763209
376 0.6956109340472888
377 0.6971371770332364
378 0.6906253801024516
379 0.7028952325116776
380 0.7042930251381303
Train R2 - DI: 0.381
Val R2 - DI: 0.335
Test R2 - DI: 0.268
381 0.6981085801210027
382 0.7004155531579022
383 0.6945772455584618
384 0.7066058008046988
385 0.6917184457984021
386 0.6979818174915929
387 0.7042628082750518
388 0.6919844908099021
389 0.7028306507722452
390 0.7003148851428835
Train R2 - DI: 0.383
Val R2 - DI: 0.337
Test R2 - DI: 0.267
391 0.6962638068370067
392 0.6927025946237708
393 0.6957420371766586
394 0.6976019433535983
395 0.6945163329015068
396 0.6969264509857341
397 0.7016574810055421
398 0.6931712586819911
399 0.6987599651659688
400 0.700017819951512
Train R2 - DI: 0.385
Val R2 - DI: 0.337
Test R2 - DI: 0.268
0.33688554366026524
Test R2 - DI: 0.268
Test R2 - DI: 0.268

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 14766799: <testjob> in cluster <dcc> Done

Job <testjob> was submitted from host <n-62-30-8> by user <s174503> in cluster <dcc> at Tue Nov 15 13:45:48 2022
Job was executed on host(s) <n-62-20-6>, in queue <gpuv100>, as user <s174503> in cluster <dcc> at Tue Nov 15 13:48:48 2022
</zhome/fd/6/127382> was used as the home directory.
</zhome/fd/6/127382/Desktop/MasterThesis/Master-thesis> was used as the working directory.
Started at Tue Nov 15 13:48:48 2022
Terminated at Tue Nov 15 20:46:32 2022
Results reported at Tue Nov 15 20:46:32 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J testjob
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 10:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -o outputs/gpu_%J.out
#BSUB -e outputs/errors/gpu_%J.err

nvidia-smi
module load cuda/11.6

/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery

source $HOME/miniconda3/bin/activate
source venv_1/bin/activate

python3 main.py CNN_simple 128 1e-6 1 100 shuffle_sgd_1wd01 99 SGD
python3 main.py CNN_simple 128 1e-6 1 300 shuffle_sgd_1wd1 99 SGD
python3 main.py CNN_simple 128 1e-6 1 400 shuffle_sgd_1wd10 99 SGD
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22184.81 sec.
    Max Memory :                                 2252 MB
    Average Memory :                             2221.40 MB
    Total Requested Memory :                     5120.00 MB
    Delta Memory :                               2868.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   25065 sec.
    Turnaround time :                            25244 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/errors/gpu_14766799.err> for stderr output of this job.

