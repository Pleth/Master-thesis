Mon Nov 14 17:02:27 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:58:00.0 Off |                    0 |
| N/A   31C    P0    37W / 250W |      0MiB / 32768MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-PCIE-32GB"
  CUDA Driver Version / Runtime Version          11.8 / 11.6
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 32511 MBytes (34089926656 bytes)
  (080) Multiprocessors, (064) CUDA Cores/MP:    5120 CUDA Cores
  GPU Max Clock rate:                            1380 MHz (1.38 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 7 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 88 / 0
  Compute Mode:
     < Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.8, CUDA Runtime Version = 11.6, NumDevs = 1
Result = PASS
CNN_simple
batch_size =  128 lr =  1e-08 wd =  1.0
5580 1000 1000
cuda:0
Using Adam
1 3.632986003267295
2 3.1977570080842597
3 2.824642079021768
4 2.489565130203001
5 2.230262835991425
6 1.9992371618106801
7 1.8116465887288467
8 1.6723837998605544
9 1.540448184167185
10 1.4225970861305046
Train R2 - DI: -0.278
Val R2 - DI: -0.246
Test R2 - DI: -0.299
11 1.3376344176603474
12 1.2839828707411298
13 1.2460952576770576
14 1.1992969608648703
15 1.158637023484835
16 1.1281342072298877
17 1.1277031493443315
18 1.1052549334837116
19 1.099714265929328
20 1.0736749349956445
Train R2 - DI: 0.048
Val R2 - DI: 0.040
Test R2 - DI: 0.041
21 1.069490443933822
22 1.0461545057194208
23 1.0335951529523377
24 1.023564448493356
25 1.0215300918907249
26 0.9931724899985884
27 1.0073800540312217
28 1.0021367398641443
29 0.9837254586612879
30 0.982735590780935
Train R2 - DI: 0.134
Val R2 - DI: 0.123
Test R2 - DI: 0.142
31 0.9762883211122192
32 0.961424051903482
33 0.9650521022444557
34 0.9541606612530233
35 0.9701200151101663
36 0.9444969859174502
37 0.9405958292304829
38 0.9308732455776584
39 0.9367022600652496
40 0.9233265623824144
Train R2 - DI: 0.180
Val R2 - DI: 0.175
Test R2 - DI: 0.190
41 0.9271858152950109
42 0.9294506970272269
43 0.9261547968379058
44 0.9137617515834001
45 0.9235429211329388
46 0.8964199209298711
47 0.9133789141545586
48 0.9010880239548221
49 0.9119519414867552
50 0.8950611641757377
Train R2 - DI: 0.216
Val R2 - DI: 0.205
Test R2 - DI: 0.231
51 0.9011640995206799
52 0.880865464971057
53 0.8862631292326049
54 0.8900642192919195
55 0.8810484968633208
56 0.8835899626909618
57 0.8781832173733728
58 0.8816468431103615
59 0.8818401887425386
60 0.8756444201674513
Train R2 - DI: 0.237
Val R2 - DI: 0.226
Test R2 - DI: 0.254
61 0.8712478614622546
62 0.8674826755318591
63 0.8626302387124749
64 0.8672737805646807
65 0.8654683334853059
66 0.8620032941568709
67 0.856579451449883
68 0.874216045530039
69 0.8499453952662833
70 0.8584675231287556
Train R2 - DI: 0.254
Val R2 - DI: 0.239
Test R2 - DI: 0.272
71 0.8638609369168572
72 0.852154193898683
73 0.8558366396521154
74 0.8526079610684439
75 0.8352490211473144
76 0.8545859456062317
77 0.8369919686334535
78 0.8451454748816815
79 0.8325259045888019
80 0.8343967312980296
Train R2 - DI: 0.266
Val R2 - DI: 0.250
Test R2 - DI: 0.281
81 0.8398322790327037
82 0.841011701177098
83 0.8238793854645077
84 0.8395370804708063
85 0.8416628752558035
86 0.8445801083759595
87 0.8293601483854341
88 0.8257263456194204
89 0.8250062933959414
90 0.8308634048294423
Train R2 - DI: 0.279
Val R2 - DI: 0.256
Test R2 - DI: 0.295
91 0.8193911402456222
92 0.8235660789260727
93 0.834093287896939
94 0.813929800192515
95 0.8307661254773431
96 0.8197038887222181
97 0.827278618957834
98 0.8177778224363976
99 0.8190357720125533
100 0.8202551837890378
Train R2 - DI: 0.287
Val R2 - DI: 0.263
Test R2 - DI: 0.302
101 0.8162592117931681
102 0.8131078259492006
103 0.8043868908745414
104 0.8147977681142882
105 0.8248907079833383
106 0.8113490259348278
107 0.8237861555964289
108 0.8157971989723944
109 0.8060967366755223
110 0.8078492130857214
Train R2 - DI: 0.295
Val R2 - DI: 0.268
Test R2 - DI: 0.309
111 0.8012066610397831
112 0.8114310204341847
113 0.7958154016925443
114 0.8009831935274131
115 0.808749097008859
116 0.8127442041178331
117 0.8045218906094951
118 0.8018240134775853
119 0.8089552825497043
120 0.7897210861619656
Train R2 - DI: 0.303
Val R2 - DI: 0.271
Test R2 - DI: 0.315
121 0.7988078461752998
122 0.7960915162144596
123 0.780649149887878
124 0.801699652124904
125 0.797125500675598
126 0.7819738882416892
127 0.7951143123770272
128 0.7959367169274224
129 0.7918488972503225
130 0.78261773364091
Train R2 - DI: 0.310
Val R2 - DI: 0.273
Test R2 - DI: 0.320
131 0.7895168902626174
132 0.7898686943942927
133 0.7942679753867529
134 0.7912993632337099
135 0.7857286751056658
136 0.7879513114583963
137 0.7817189955369546
138 0.7886838374599334
139 0.7769067269926857
140 0.7793871114758181
Train R2 - DI: 0.309
Val R2 - DI: 0.278
Test R2 - DI: 0.318
141 0.7901590176380663
142 0.7824035617613023
143 0.7849177070843276
144 0.7760124979053347
145 0.7723513779674379
146 0.7778632625029506
147 0.7905815662448978
148 0.7713417203195634
149 0.7926121635249012
150 0.7718135632067171
Train R2 - DI: 0.319
Val R2 - DI: 0.281
Test R2 - DI: 0.325
151 0.7831158358136385
152 0.7795837478398422
153 0.7799832721337623
154 0.7848106693196041
155 0.7821290021301598
156 0.7697184678046934
157 0.7749448055434826
158 0.7660840792040671
159 0.775304858616176
160 0.7735015637131147
Train R2 - DI: 0.324
Val R2 - DI: 0.283
Test R2 - DI: 0.329
161 0.7707548048761156
162 0.7637245929796636
163 0.777879861648792
164 0.7698001364225983
165 0.7682628591428093
166 0.7579036954055978
167 0.7616293574746792
168 0.7680220422778933
169 0.7676493997642216
170 0.7607227974467807
Train R2 - DI: 0.330
Val R2 - DI: 0.284
Test R2 - DI: 0.333
171 0.7674685902492975
172 0.7673006955440753
173 0.7577123850477212
174 0.7576500217119853
175 0.7708525520926308
176 0.7754202183429486
177 0.7648034710183366
178 0.7625949446872998
179 0.7661372743199804
180 0.7575932661265028
Train R2 - DI: 0.335
Val R2 - DI: 0.287
Test R2 - DI: 0.335
181 0.759380437738152
182 0.7562230446432654
183 0.7599661441259487
184 0.7541956027348836
185 0.7498864901108554
186 0.75995263566253
187 0.7556394155734756
188 0.7537184904553129
189 0.7602039152148804
190 0.7553115147843583
Train R2 - DI: 0.337
Val R2 - DI: 0.288
Test R2 - DI: 0.335
191 0.7561061979194695
192 0.7530319487749462
193 0.7648045746229029
194 0.7461587082527872
195 0.7539927232650019
196 0.7529936306792775
197 0.7411805577175592
198 0.7458471698572986
199 0.7428989019445194
200 0.7456829919182699
Train R2 - DI: 0.335
Val R2 - DI: 0.289
Test R2 - DI: 0.331
0.2892020022677788
Test R2 - DI: 0.331
Test R2 - DI: 0.331
CNN_simple
batch_size =  128 lr =  1e-08 wd =  10.0
5580 1000 1000
cuda:0
Using Adam
1 3.391031687063128
2 3.0855580133349236
3 2.826585848613452
4 2.587848848424932
5 2.384559623485825
6 2.2201284786279056
7 2.065924442284423
8 1.95590314403657
9 1.85413036354981
10 1.7530279217655087
Train R2 - DI: -0.643
Val R2 - DI: -0.590
Test R2 - DI: -0.666
11 1.658451370440931
12 1.6229946455220594
13 1.5583191820370255
14 1.485783540305271
15 1.4536418081611715
16 1.4276317193943968
17 1.3973215719277714
18 1.361463778506043
19 1.3350788793256205
20 1.321379530814386
Train R2 - DI: -0.221
Val R2 - DI: -0.188
Test R2 - DI: -0.239
21 1.3228571919984715
22 1.2826143074206553
23 1.2649113947345365
24 1.260339370252411
25 1.241775462447956
26 1.2378299047442747
27 1.2350204465209798
28 1.195996896938611
29 1.2027817130516079
30 1.1832113377936853
Train R2 - DI: -0.091
Val R2 - DI: -0.065
Test R2 - DI: -0.106
31 1.176952653631942
32 1.178852293226454
33 1.1681047073829132
34 1.1669236242984786
35 1.1535903270099326
36 1.1450636088634478
37 1.1401062876520192
38 1.1348315710662513
39 1.1377724503958098
40 1.1347719114741117
Train R2 - DI: -0.018
Val R2 - DI: 0.003
Test R2 - DI: -0.031
41 1.1219915415651054
42 1.1261483019825378
43 1.1156571157516972
44 1.0881694471536998
45 1.0802105100351422
46 1.1093832396264571
47 1.0979773410332245
48 1.084812612601933
49 1.0835971804075344
50 1.0879934456186056
Train R2 - DI: 0.018
Val R2 - DI: 0.036
Test R2 - DI: 0.007
51 1.0711446971448946
52 1.0857395976247752
53 1.0684580921272222
54 1.0682366410463942
55 1.0533797702481669
56 1.0635720694364186
57 1.0570456154457557
58 1.0491702059263823
59 1.0536959719914263
60 1.0382300254691885
Train R2 - DI: 0.062
Val R2 - DI: 0.078
Test R2 - DI: 0.051
61 1.0482515407719493
62 1.0239643347306064
63 1.0289067098316753
64 1.035135839147807
65 1.0401081578278628
66 1.0351504418585036
67 1.037463895479838
68 1.0241401519826663
69 1.0176527905207808
70 1.0128979517994816
Train R2 - DI: 0.085
Val R2 - DI: 0.096
Test R2 - DI: 0.071
71 1.018859855333964
72 1.0218210368173524
73 1.0115791619037642
74 1.0236923662137813
75 1.0035614499054502
76 0.9985449190208134
77 0.9988203957089387
78 1.0064923764129694
79 0.9989184361632152
80 1.0029252606908052
Train R2 - DI: 0.113
Val R2 - DI: 0.124
Test R2 - DI: 0.100
81 0.9930310633874708
82 0.9966658644778754
83 1.0036714593142164
84 0.9902763885836448
85 0.9829701339472152
86 0.9904081663777752
87 0.9862609636826327
88 0.9821676825964323
89 0.9944170443387869
90 0.9742852884381475
Train R2 - DI: 0.127
Val R2 - DI: 0.134
Test R2 - DI: 0.113
91 0.9834357194148512
92 0.9834877464933635
93 0.966730166806115
94 0.975751745059926
95 0.9761972558968384
96 0.981320929057282
97 0.962870613306654
98 0.9638638976654271
99 0.9819942104346436
100 0.9640768939021668
Train R2 - DI: 0.140
Val R2 - DI: 0.145
Test R2 - DI: 0.126
101 0.967772421999217
102 0.9622350846567461
103 0.9721241475860705
104 0.9546409085232724
105 0.9697282134418419
106 0.9566250487467721
107 0.9561398142127581
108 0.9592746734191867
109 0.943126455985517
110 0.9505764915097145
Train R2 - DI: 0.150
Val R2 - DI: 0.152
Test R2 - DI: 0.134
111 0.9424549403583704
112 0.9412371664491606
113 0.9522072302825134
114 0.9470756433770648
115 0.9435783646439994
116 0.9348485272417786
117 0.9455528711759916
118 0.9294368854133032
119 0.9418459431672181
120 0.9312402701719688
Train R2 - DI: 0.171
Val R2 - DI: 0.171
Test R2 - DI: 0.154
121 0.9288741877002101
122 0.935218909521684
123 0.9323103492405252
124 0.9313303860712222
125 0.9308257557585248
126 0.9352946635215513
127 0.937283002005683
128 0.9199864093548081
129 0.9452366150408236
130 0.9153840886221991
Train R2 - DI: 0.183
Val R2 - DI: 0.183
Test R2 - DI: 0.168
131 0.9292734557582486
132 0.9393547721233847
133 0.9304079028440633
134 0.929215877714123
135 0.9241308084098242
136 0.9209718391886749
137 0.9065908387143125
138 0.9163802359693793
139 0.9192909226195359
140 0.9213751862126012
Train R2 - DI: 0.192
Val R2 - DI: 0.190
Test R2 - DI: 0.176
141 0.9180213640667632
142 0.9046793783437393
143 0.90796378479209
144 0.9044439063704569
145 0.9059620191974025
146 0.9120162290484247
147 0.9118937459043277
148 0.9019390280956009
149 0.8960579111584626
150 0.9149433245368328
Train R2 - DI: 0.192
Val R2 - DI: 0.186
Test R2 - DI: 0.173
151 0.9109513202875745
152 0.8975384479782488
153 0.899774194020097
154 0.9102591454341847
155 0.902446502468492
156 0.8986955086390177
157 0.9040377710455207
158 0.9112373955360877
159 0.9035740532328151
160 0.8956566247888791
Train R2 - DI: 0.208
Val R2 - DI: 0.201
Test R2 - DI: 0.189
161 0.8992713287739771
162 0.9043125788370768
163 0.9031353733445581
164 0.8899225469985743
165 0.8851334577392934
166 0.8930864352051929
167 0.8975372546462602
168 0.8959076088389188
169 0.8947900359348584
170 0.8900619591008805
Train R2 - DI: 0.216
Val R2 - DI: 0.209
Test R2 - DI: 0.197
171 0.8927496895567918
172 0.8763880854439138
173 0.8928969277703207
174 0.8754286257596854
175 0.8782731356159333
176 0.8838230458211728
177 0.8885574440802297
178 0.882790129842724
179 0.8927756965374006
180 0.877090270801257
Train R2 - DI: 0.217
Val R2 - DI: 0.206
Test R2 - DI: 0.194
181 0.8753678588457005
182 0.8693818617892521
183 0.8657701215863655
184 0.8761913258115023
185 0.887097200526986
186 0.8713003342724188
187 0.8720888747109308
188 0.8762390193118844
189 0.8761344611003835
190 0.8705747982079838
Train R2 - DI: 0.228
Val R2 - DI: 0.217
Test R2 - DI: 0.206
191 0.8693280825905475
192 0.8729000567962619
193 0.8709921602707182
194 0.8749808445626263
195 0.8586694570425163
196 0.8658695170528999
197 0.8646963288707118
198 0.8690785674211372
199 0.8684914702155684
200 0.8601667083292451
Train R2 - DI: 0.231
Val R2 - DI: 0.218
Test R2 - DI: 0.208
201 0.8639004600090793
202 0.8601825672665805
203 0.8538887721236034
204 0.8678228656878181
205 0.861202460335147
206 0.8619318688642167
207 0.8782674283536959
208 0.8553399282544317
209 0.8638679583867391
210 0.8659588485635737
Train R2 - DI: 0.239
Val R2 - DI: 0.225
Test R2 - DI: 0.214
211 0.8525519012123026
212 0.8563326747186722
213 0.8637628636052531
214 0.8536570121310518
215 0.8546979638410725
216 0.8650931696737966
217 0.8551510321623963
218 0.8542743106042185
219 0.8673334155885977
220 0.867336422482699
Train R2 - DI: 0.238
Val R2 - DI: 0.222
Test R2 - DI: 0.211
221 0.848090105244763
222 0.8596401856791589
223 0.8571390436968923
224 0.8465578574006275
225 0.845895791181954
226 0.8462531323501286
227 0.8528960290348231
228 0.8470030181296837
229 0.8559920576310927
230 0.8510313936031847
Train R2 - DI: 0.250
Val R2 - DI: 0.233
Test R2 - DI: 0.223
231 0.8603419591876341
232 0.8523947089376416
233 0.8453431390519638
234 0.8457516069053321
235 0.8642703109744629
236 0.8460463542237504
237 0.8577871113267851
238 0.8415550085806077
239 0.8498819116623171
240 0.8468000094950413
Train R2 - DI: 0.247
Val R2 - DI: 0.231
Test R2 - DI: 0.221
241 0.8494961496322385
242 0.8447161424544549
243 0.8441591317935656
244 0.836194884136159
245 0.8467676993766566
246 0.8443844391453651
247 0.8627706504637195
248 0.8438631041075594
249 0.8434065053539891
250 0.8339179361165638
Train R2 - DI: 0.257
Val R2 - DI: 0.240
Test R2 - DI: 0.231
251 0.8454710984742769
252 0.8453657164795851
253 0.8411197320534765
254 0.835071773170143
255 0.8340085397057209
256 0.8373780362922231
257 0.8292130087866151
258 0.8391907703919222
259 0.8456336593115201
260 0.8405971034026061
Train R2 - DI: 0.259
Val R2 - DI: 0.241
Test R2 - DI: 0.231
261 0.8363619832582371
262 0.839760637625144
263 0.8269510560565525
264 0.8398167782786926
265 0.8412309902970508
266 0.8390635278489854
267 0.8391468386068993
268 0.845304729135233
269 0.8379626519791115
270 0.8276542415328351
Train R2 - DI: 0.259
Val R2 - DI: 0.240
Test R2 - DI: 0.230
271 0.8291291390268606
272 0.8244133107123837
273 0.8330820207100188
274 0.8397625130991782
275 0.83989169866808
276 0.8168204729702311
277 0.8332504958234808
278 0.8268664194264292
279 0.8395525383692916
280 0.8250143397238947
Train R2 - DI: 0.264
Val R2 - DI: 0.245
Test R2 - DI: 0.235
281 0.8352943994238385
282 0.8293464235934732
283 0.8196595348337645
284 0.8338555147570949
285 0.836259071117661
286 0.8242105674145469
287 0.8292026668039274
288 0.8289707912766378
289 0.836092205970518
290 0.8218856319304435
Train R2 - DI: 0.265
Val R2 - DI: 0.244
Test R2 - DI: 0.235
291 0.8237676053918818
292 0.8341225837293919
293 0.8313713645849604
294 0.8188154312444844
295 0.8199093443091198
296 0.820782061588807
297 0.8270688706828702
298 0.8142290313184047
299 0.8250070115998654
300 0.8242150933084522
Train R2 - DI: 0.266
Val R2 - DI: 0.244
Test R2 - DI: 0.234
301 0.8241957224825377
302 0.8171755759946762
303 0.8124249253649011
304 0.8133289970804713
305 0.8227341413070651
306 0.8243567885891083
307 0.8259189925313423
308 0.8244697978846915
309 0.8156925926071769
310 0.8158961263608762
Train R2 - DI: 0.277
Val R2 - DI: 0.253
Test R2 - DI: 0.245
311 0.8036332051813816
312 0.8178509626764551
313 0.8173672044576282
314 0.8135023649020862
315 0.811483614760915
316 0.82449005051753
317 0.8246355293472181
318 0.8136128436707254
319 0.8052662447361963
320 0.8055107430745196
Train R2 - DI: 0.276
Val R2 - DI: 0.252
Test R2 - DI: 0.243
321 0.8238394663325347
322 0.8192688195081594
323 0.8181858145635188
324 0.815343082036596
325 0.8060949248225031
326 0.8125810892351212
327 0.808925520903748
328 0.81223549287379
329 0.8105024238641116
330 0.8020102016387447
Train R2 - DI: 0.283
Val R2 - DI: 0.259
Test R2 - DI: 0.250
331 0.8010669514697085
332 0.8193983702676698
333 0.8131778922986813
334 0.7942049769945042
335 0.8045903404126458
336 0.7968326622439968
337 0.8049785669986492
338 0.8095214041330481
339 0.807192394425792
340 0.8099827216944814
Train R2 - DI: 0.281
Val R2 - DI: 0.256
Test R2 - DI: 0.247
341 0.8050018282346828
342 0.814311365884692
343 0.8054514180802103
344 0.8099449608915595
345 0.8063228465322952
346 0.8068491696456854
347 0.8049264901855085
348 0.8096467631264826
349 0.8106350041632157
350 0.8071438087357415
Train R2 - DI: 0.284
Val R2 - DI: 0.258
Test R2 - DI: 0.249
351 0.8061169591428559
352 0.8066344490187997
353 0.8084251695209079
354 0.8017575924969061
355 0.8024742390947103
356 0.8116497446131963
357 0.805380939198224
358 0.791538187637124
359 0.7973831314767134
360 0.7963831885313902
Train R2 - DI: 0.288
Val R2 - DI: 0.261
Test R2 - DI: 0.253
361 0.8061613893423456
362 0.7926407438025252
363 0.8135035869895771
364 0.8009576917976462
365 0.8002326625649647
366 0.8112802053437865
367 0.8066539394812772
368 0.8130536080261285
369 0.8071762759625698
370 0.7981997746720536
Train R2 - DI: 0.280
Val R2 - DI: 0.251
Test R2 - DI: 0.243
371 0.7838306523138477
372 0.807147608136618
373 0.8033104670945034
374 0.7997753403520071
375 0.7992091930468023
376 0.8021486533585415
377 0.7965699032643363
378 0.7921873579315815
379 0.8090872154440931
380 0.8026200374822036
Train R2 - DI: 0.289
Val R2 - DI: 0.261
Test R2 - DI: 0.253
381 0.8058482581142029
382 0.7965365487187567
383 0.7947955882250195
384 0.7999009710486217
385 0.8000120461628001
386 0.8031805578098502
387 0.7941860058401647
388 0.795691931845894
389 0.7978420990769581
390 0.8067283247534092
Train R2 - DI: 0.282
Val R2 - DI: 0.253
Test R2 - DI: 0.244
391 0.7912778711660788
392 0.7944956818361864
393 0.801882714738128
394 0.7927408505084267
395 0.7856571438064712
396 0.7945774387715111
397 0.7909458779092331
398 0.797924214323789
399 0.7888816233604184
400 0.7957639343422374
Train R2 - DI: 0.293
Val R2 - DI: 0.263
Test R2 - DI: 0.255
401 0.7959680816605954
402 0.7975185675860306
403 0.7940806236318363
404 0.7869291308532906
405 0.8004136927666202
406 0.7799979965319342
407 0.7927830464523753
408 0.7985580964754987
409 0.7895818238617272
410 0.8038451216981403
Train R2 - DI: 0.293
Val R2 - DI: 0.262
Test R2 - DI: 0.254
411 0.8018341839954417
412 0.7999281439302642
413 0.7862369712535626
414 0.7865828838399661
415 0.796909859829906
416 0.7904601620089623
417 0.7841721303574073
418 0.7904283377432054
419 0.7920679661108174
420 0.7811533350243791
Train R2 - DI: 0.291
Val R2 - DI: 0.260
Test R2 - DI: 0.252
421 0.803985141126913
422 0.7955653652922654
423 0.794101736622472
424 0.791509218027942
425 0.7907379933582839
426 0.7795536726179089
427 0.7894701421901744
428 0.7845606094192861
429 0.7747993111183139
430 0.7792298530165013
Train R2 - DI: 0.303
Val R2 - DI: 0.272
Test R2 - DI: 0.264
431 0.7828142840802456
432 0.7858982493800502
433 0.7825130507937469
434 0.7827702761550958
435 0.7828343164963534
436 0.7891781366854158
437 0.7923888370554935
438 0.7829145771200939
439 0.7906663899780602
440 0.7947628410913611
Train R2 - DI: 0.303
Val R2 - DI: 0.272
Test R2 - DI: 0.263
441 0.7845740448616739
442 0.7819968287662793
443 0.7991842769807385
444 0.7877994553589907
445 0.7847968245065341
446 0.78913258502133
447 0.7862001210557944
448 0.8018666202449457
449 0.7852029353487021
450 0.783375771541322
Train R2 - DI: 0.304
Val R2 - DI: 0.272
Test R2 - DI: 0.264
451 0.7842441241373725
452 0.7905939672582893
453 0.7767070918100282
454 0.7715877616704578
455 0.7907847115215862
456 0.7780320681124178
457 0.7811709990210858
458 0.7829388374496105
459 0.784179063723506
460 0.7905659254733807
Train R2 - DI: 0.304
Val R2 - DI: 0.272
Test R2 - DI: 0.263
461 0.7838087263500392
462 0.7776558514564268
463 0.7802365143239285
464 0.7815510258025166
465 0.7729071162934799
466 0.775841557894129
467 0.774433041558898
468 0.7791992978383137
469 0.7769607639654563
470 0.7829790325574978
Train R2 - DI: 0.304
Val R2 - DI: 0.270
Test R2 - DI: 0.262
471 0.7743539693107742
472 0.7792211974820783
473 0.7816232589837898
474 0.778652273113155
475 0.7803718498958054
476 0.7789270561228516
477 0.7760694464047749
478 0.7697857562786362
479 0.7664117831483109
480 0.7762940845181865
Train R2 - DI: 0.306
Val R2 - DI: 0.271
Test R2 - DI: 0.264
481 0.7761920568763568
482 0.7837547193291367
483 0.7878112106340334
484 0.7761613536051952
485 0.7861235427600082
486 0.777588376392173
487 0.7837018875665562
488 0.7757115847320967
489 0.7769278798906607
490 0.7773982522735459
Train R2 - DI: 0.309
Val R2 - DI: 0.274
Test R2 - DI: 0.267
491 0.771327239253615
492 0.7675951279619688
493 0.7673016582338613
494 0.7777688878411461
495 0.7641976993143772
496 0.7655357298030648
497 0.7714752878766761
498 0.7787498122902327
499 0.7691042981694676
500 0.76658129251986
Train R2 - DI: 0.311
Val R2 - DI: 0.275
Test R2 - DI: 0.267
0.2753554820831172
Test R2 - DI: 0.267
Test R2 - DI: 0.267

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 14754423: <testjob> in cluster <dcc> Done

Job <testjob> was submitted from host <n-62-30-8> by user <s174503> in cluster <dcc> at Mon Nov 14 16:47:20 2022
Job was executed on host(s) <n-62-11-15>, in queue <gpuv100>, as user <s174503> in cluster <dcc> at Mon Nov 14 17:02:26 2022
</zhome/fd/6/127382> was used as the home directory.
</zhome/fd/6/127382/Desktop/MasterThesis/Master-thesis> was used as the working directory.
Started at Mon Nov 14 17:02:26 2022
Terminated at Mon Nov 14 22:39:54 2022
Results reported at Mon Nov 14 22:39:54 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J testjob
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 08:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -o outputs/gpu_%J.out
#BSUB -e outputs/errors/gpu_%J.err

nvidia-smi
module load cuda/11.6

/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery

source $HOME/miniconda3/bin/activate
source venv_1/bin/activate

python3 main.py CNN_simple 128 1e-8 1 200 shuffle_2wd1 99 adam
python3 main.py CNN_simple 128 1e-8 10 500 shuffle_2wd10 99 adam
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   18371.38 sec.
    Max Memory :                                 2448 MB
    Average Memory :                             2223.13 MB
    Total Requested Memory :                     5120.00 MB
    Delta Memory :                               2672.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   20248 sec.
    Turnaround time :                            21154 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/errors/gpu_14754423.err> for stderr output of this job.

