Wed Nov  9 19:28:13 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:58:00.0 Off |                    0 |
| N/A   28C    P0    32W / 250W |      0MiB / 32768MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-PCIE-32GB"
  CUDA Driver Version / Runtime Version          11.7 / 11.6
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 32511 MBytes (34089926656 bytes)
  (080) Multiprocessors, (064) CUDA Cores/MP:    5120 CUDA Cores
  GPU Max Clock rate:                            1380 MHz (1.38 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 7 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 88 / 0
  Compute Mode:
     < Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.7, CUDA Runtime Version = 11.6, NumDevs = 1
Result = PASS
Deep_google
batch_size =  128 lr =  1e-06 wd =  20.0
5580 1000 1000
cuda:0
1 4.518608936870397
2 4.284121882189132
3 4.063187528425647
4 3.896312309251464
5 3.6732281819893897
6 3.5161712301247436
7 3.408598974186887
8 3.317484437778432
9 3.205097114398915
10 3.0891435308695696
Train R2 - DI: -1.773
Val R2 - DI: -1.726
Test R2 - DI: -1.755
11 3.0066554529265264
12 2.9389899609336716
13 2.8726978963421237
14 2.811678741653333
15 2.739454258129161
16 2.6795811424118643
17 2.652583274362762
18 2.565235251765097
19 2.508639345203249
20 2.5013198531229435
Train R2 - DI: -1.242
Val R2 - DI: -1.202
Test R2 - DI: -1.218
21 2.4271581619016587
22 2.4240890219220126
23 2.374120041119155
24 2.3434305980641357
25 2.2955487523027647
26 2.2932298545769036
27 2.2595258213713176
28 2.218318413149926
29 2.191469794447704
30 2.1612390707897884
Train R2 - DI: -0.920
Val R2 - DI: -0.887
Test R2 - DI: -0.896
31 2.1348910637653855
32 2.0896121874505047
33 2.0929785357581245
34 2.066281396428317
35 2.0341049517354657
36 2.009839177900745
37 1.9898394371019041
38 1.9778672942978508
39 1.9701438509007936
40 1.9386081418683452
Train R2 - DI: -0.751
Val R2 - DI: -0.722
Test R2 - DI: -0.728
41 1.9307963689168295
42 1.907666576293207
43 1.886598558750631
44 1.8645216637614808
45 1.864137999900353
46 1.8335941245478968
47 1.826156818653093
48 1.8059797904824697
49 1.7876465582078502
50 1.7762550261712844
Train R2 - DI: -0.589
Val R2 - DI: -0.567
Test R2 - DI: -0.568
51 1.751674748577952
52 1.7218528720213093
53 1.7470598653225915
54 1.7198129599239664
55 1.7173945797814263
56 1.6827585663846745
57 1.6784469491692
58 1.6736010680489215
59 1.6786370787569271
60 1.6514901024466346
Train R2 - DI: -0.493
Val R2 - DI: -0.473
Test R2 - DI: -0.473
61 1.64642809505531
62 1.6131455403502268
63 1.5967545893029926
64 1.5855672017647802
65 1.5913988045894116
66 1.5759785198396252
67 1.5640949584249955
68 1.5500941185113777
69 1.5465730187713458
70 1.5310211288458986
Train R2 - DI: -0.376
Val R2 - DI: -0.362
Test R2 - DI: -0.358
71 1.5310994905382929
72 1.5102203668232033
73 1.5399883485609485
74 1.4909181937521931
75 1.4888550619925223
76 1.4747890686048828
77 1.478698382497261
78 1.4518891292660894
79 1.460408174179788
80 1.4450240254829434
Train R2 - DI: -0.294
Val R2 - DI: -0.285
Test R2 - DI: -0.279
81 1.4322833963619765
82 1.436732660143179
83 1.4335600112074165
84 1.44035700512616
85 1.4342712973181064
86 1.409802381624885
87 1.3967776152395432
88 1.3892650201756467
89 1.375994496362611
90 1.3693815197995913
Train R2 - DI: -0.238
Val R2 - DI: -0.233
Test R2 - DI: -0.224
91 1.3831592587159953
92 1.360007520815805
93 1.3595799299123894
94 1.3615003400378758
95 1.3543527006675693
96 1.333866276108663
97 1.3492673779046664
98 1.3393515546689323
99 1.3287541486029129
100 1.318878094697084
Train R2 - DI: -0.190
Val R2 - DI: -0.189
Test R2 - DI: -0.177
101 1.311051034158276
102 1.2913916973230233
103 1.3126425988357981
104 1.3074307053747143
105 1.2749443015744608
106 1.2945993956699167
107 1.3048404212493623
108 1.2900021669257926
109 1.280027973139158
110 1.2706599843972046
Train R2 - DI: -0.157
Val R2 - DI: -0.158
Test R2 - DI: -0.145
111 1.2641988004834848
112 1.2570236650419064
113 1.2639451752854076
114 1.2608567001999065
115 1.2550799310848277
116 1.2448535773916485
117 1.2319907525961544
118 1.2499575621765575
119 1.2377651029162937
120 1.2275319357499428
Train R2 - DI: -0.139
Val R2 - DI: -0.142
Test R2 - DI: -0.128
121 1.2206325426751141
122 1.2196111111658021
123 1.2280485837690291
124 1.2273320572350614
125 1.1876124887483521
126 1.2039242700009363
127 1.2067149796366263
128 1.2006323866946722
129 1.211642615769499
130 1.1770025476332633
Train R2 - DI: -0.074
Val R2 - DI: -0.084
Test R2 - DI: -0.067
131 1.2006649943662802
132 1.191565102146518
133 1.1857697527041144
134 1.1850537428291894
135 1.1908247302509978
136 1.1771645448541128
137 1.1763592884104739
138 1.1688023668036238
139 1.1574684787822027
140 1.1621589136807295
Train R2 - DI: -0.064
Val R2 - DI: -0.074
Test R2 - DI: -0.057
141 1.1675446547915005
142 1.1624654205041973
143 1.1553238861022457
144 1.1486069873242395
145 1.1357787281808887
146 1.1474913013451415
147 1.136946384710223
148 1.157543302265974
149 1.128341358707797
150 1.1247982520783675
Train R2 - DI: -0.043
Val R2 - DI: -0.055
Test R2 - DI: -0.037
151 1.128421411035736
152 1.1305696332753772
153 1.1254753332411516
154 1.1240017656784331
155 1.1300330889267733
156 1.116068199287606
157 1.1143085962555315
158 1.1115277541581021
159 1.1148063386212967
160 1.1097619970212274
Train R2 - DI: -0.036
Val R2 - DI: -0.049
Test R2 - DI: -0.029
161 1.1071699027092226
162 1.1054505296078208
163 1.1014144345423653
164 1.09660246547405
165 1.088587276333122
166 1.0969448399800126
167 1.0920212318393065
168 1.1003592268967715
169 1.0803500626249554
170 1.0862380790454085
Train R2 - DI: -0.008
Val R2 - DI: -0.024
Test R2 - DI: -0.002
171 1.091312819826133
172 1.0928138818364843
173 1.080730873324965
174 1.0733961106201226
175 1.074148690828713
176 1.0875975980553576
177 1.078025022031586
178 1.0683233454235992
179 1.0625707839979492
180 1.0692918385228802
Train R2 - DI: 0.019
Val R2 - DI: -0.001
Test R2 - DI: 0.024
181 1.0663722606542718
182 1.068764484227772
183 1.0686011473337809
184 1.0655764933555356
185 1.0589144207670698
186 1.0526506613659603
187 1.0611395005256898
188 1.0642665105054028
189 1.057417838120546
190 1.053502928740662
Train R2 - DI: 0.028
Val R2 - DI: 0.008
Test R2 - DI: 0.033
191 1.0463652832960997
192 1.0540957951203898
193 1.0579631564437701
194 1.058532950143233
195 1.0565810042042887
196 1.050967094206041
197 1.0452642928314893
198 1.0397044131405464
199 1.036296639647535
200 1.0413990898371597
Train R2 - DI: 0.041
Val R2 - DI: 0.020
Test R2 - DI: 0.045
201 1.045073949051587
202 1.031693001630913
203 1.0393062931235117
204 1.0326698119495077
205 1.0390950108087191
206 1.0390238009046056
207 1.030794519250111
208 1.0311066091701548
209 1.0389877882909604
210 1.0184811902302568
Train R2 - DI: 0.042
Val R2 - DI: 0.020
Test R2 - DI: 0.047
211 1.0388068252566895
212 1.0294349305091366
213 1.0307510082866984
214 1.022144347450639
215 1.0321613455331453
216 1.024779823347659
217 1.025126154021123
218 1.0210275406905827
219 1.021413737770477
220 1.0308865060088455
Train R2 - DI: 0.055
Val R2 - DI: 0.031
Test R2 - DI: 0.059
221 1.0129165237095195
222 1.0180167857891342
223 1.022477814031758
224 1.0149723405479103
225 1.0199746385697395
226 1.0168250019832323
227 1.0163698998403379
228 1.0144097068403783
229 1.0030634839047667
230 1.013755418963757
Train R2 - DI: 0.062
Val R2 - DI: 0.038
Test R2 - DI: 0.066
231 1.0026589686298029
232 1.009707234922703
233 1.0060015842478762
234 1.0172956727311602
235 0.9978632318930813
236 1.0098618356130455
237 1.0061251107509845
238 1.0138952922222861
239 0.9998878668713314
240 1.0083459563580037
Train R2 - DI: 0.080
Val R2 - DI: 0.052
Test R2 - DI: 0.082
241 1.0021424169608768
242 1.0024642019716214
243 1.0019381153968072
244 0.9984797505494941
245 1.0078504183813664
246 0.9922163180552931
247 1.0065203377422893
248 1.0008732707697003
249 1.0016420450689119
250 0.9881184811660466
Train R2 - DI: 0.066
Val R2 - DI: 0.040
Test R2 - DI: 0.071
251 0.9921638726333564
252 0.9971029260252539
253 0.995936888691345
254 0.99240917369029
255 0.9978049626059857
256 0.9956840004117685
257 1.000353059973768
258 0.9996428015411541
259 0.9885735380606839
260 0.9913131415630327
Train R2 - DI: 0.088
Val R2 - DI: 0.058
Test R2 - DI: 0.092
261 0.9951579281933419
262 0.995506263291964
263 0.9977319978898571
264 0.9965886992792929
265 0.9992933374151961
266 0.9977114107019158
267 0.9858642758861664
268 0.978787111253294
269 0.9891736636879623
270 0.9907118507610855
Train R2 - DI: 0.078
Val R2 - DI: 0.049
Test R2 - DI: 0.083
271 0.9927794455627387
272 0.9940000748976157
273 0.9848985748479016
274 0.985253202957919
275 0.9897790324303412
276 0.9901462514767937
277 0.982956181888512
278 0.9928176663682452
279 0.9825660986712329
280 0.987137415844907
Train R2 - DI: 0.075
Val R2 - DI: 0.046
Test R2 - DI: 0.081
281 0.9852969055961964
282 0.9702872166069605
283 0.9813076460233299
284 0.9848763911100271
285 0.9832814061940784
286 0.9841057508222518
287 0.9839454603024281
288 0.9757640174640122
289 0.9782053902157746
290 0.9832664110327279
Train R2 - DI: 0.090
Val R2 - DI: 0.058
Test R2 - DI: 0.094
291 0.9786797842244521
292 0.9823282749422135
293 0.9785081299829654
294 0.9800772703676668
295 0.9796342002020941
296 0.9836456000163991
297 0.9793025495758193
298 0.9741072708133302
299 0.973822572838021
300 0.9799323773298639
Train R2 - DI: 0.085
Val R2 - DI: 0.054
Test R2 - DI: 0.090
301 0.9778210128507306
302 0.9774176516413261
303 0.9796916261368755
304 0.981707475689577
305 0.9757975008325338
306 0.9744979669970851
307 0.9749544149231313
308 0.9767227268133539
309 0.978100372386235
310 0.9783924356583626
Train R2 - DI: 0.106
Val R2 - DI: 0.070
Test R2 - DI: 0.109
311 0.9707232982881607
312 0.9721461453318169
313 0.9738056296516063
314 0.9758681249874894
315 0.9779542062444926
316 0.975332994358514
317 0.9669165415148582
318 0.9777469309427405
319 0.9786753912553138
320 0.9631117022592962
Train R2 - DI: 0.096
Val R2 - DI: 0.062
Test R2 - DI: 0.100
321 0.9737717863479396
322 0.9827128418884824
323 0.9712778362749298
324 0.9687688681387132
325 0.9790146438878924
326 0.9678576645458044
327 0.9720220314131842
328 0.970448932938251
329 0.9679055995838617
330 0.9665072172773355
Train R2 - DI: 0.093
Val R2 - DI: 0.059
Test R2 - DI: 0.099
331 0.9675807957580868
332 0.971523070933571
333 0.967285304342974
334 0.9696136278063593
335 0.9738851886923595
336 0.9748140235101023
337 0.9687151827265285
338 0.9687392860330561
339 0.9659609880071387
340 0.9698180153805722
Train R2 - DI: 0.104
Val R2 - DI: 0.068
Test R2 - DI: 0.108
341 0.9728472405864347
342 0.9673987007055659
343 0.9676448761348656
344 0.9628716183392377
345 0.9688486639316791
346 0.9598079186613842
347 0.966260733783886
348 0.9670065076547711
349 0.967485070143122
350 0.9656139594679665
Train R2 - DI: 0.095
Val R2 - DI: 0.061
Test R2 - DI: 0.100
351 0.9661554415166165
352 0.9681537429064405
353 0.9660676383630349
354 0.9641522965550849
355 0.9587569122673363
356 0.9737109312447169
357 0.9630917646124372
358 0.9664624429518177
359 0.9720517121335511
360 0.964228242828
Train R2 - DI: 0.092
Val R2 - DI: 0.058
Test R2 - DI: 0.098
361 0.9653352026443754
362 0.9678911669279939
363 0.9631096581831627
364 0.9631706467666079
365 0.9651005736388614
366 0.9570307279573119
367 0.9661370992660523
368 0.962748868234696
369 0.9668874196254225
370 0.9695975917641835
Train R2 - DI: 0.091
Val R2 - DI: 0.058
Test R2 - DI: 0.096
371 0.9680930282907246
372 0.9637246864670921
373 0.9640791369168135
374 0.9701792020524275
375 0.959334402785079
376 0.960880636015246
377 0.9683470082966658
378 0.965051261199418
379 0.9593492033233779
380 0.9751032607529753
Train R2 - DI: 0.099
Val R2 - DI: 0.064
Test R2 - DI: 0.104
381 0.9632464062783026
382 0.9662718855779231
383 0.9630222117174484
384 0.9674950135224182
385 0.9669843060995943
386 0.9564200052651026
387 0.9585962301086781
388 0.9653725427111417
389 0.9629120996348747
390 0.9676852894940257
Train R2 - DI: 0.106
Val R2 - DI: 0.071
Test R2 - DI: 0.110
391 0.9653995747634587
392 0.9604921728906666
393 0.9644756883703253
394 0.9562650754033024
395 0.96323464617507
396 0.9589582326164382
397 0.955974540488267
398 0.9644206104312746
399 0.9648977671045557
400 0.9591590214801091
Train R2 - DI: 0.103
Val R2 - DI: 0.069
Test R2 - DI: 0.107
401 0.957863030382382
402 0.9560052922122367
403 0.9585528850128147
404 0.9652819374128909
405 0.9560942501150151
406 0.9624194487448662
407 0.9588840074436639
408 0.9563193663901326
409 0.9570863984391681
410 0.953469328641037
Train R2 - DI: 0.107
Val R2 - DI: 0.073
Test R2 - DI: 0.111
411 0.9562753100549021
412 0.9543599527796537
413 0.9622276392461578
414 0.9528301578268783
415 0.9575602998870248
416 0.9615279784766576
417 0.9571491829383331
418 0.9572808866859764
419 0.9535401825409209
420 0.9549751175774468
Train R2 - DI: 0.102
Val R2 - DI: 0.069
Test R2 - DI: 0.107
421 0.9672905718553878
422 0.9533945302809438
423 0.9573246990908004
424 0.9500884982420125
425 0.9509152075723081
426 0.946032651479099
427 0.9628153607409488
428 0.956120633395342
429 0.9488504569590306
430 0.9487204124850611
Train R2 - DI: 0.114
Val R2 - DI: 0.079
Test R2 - DI: 0.117
431 0.9488793570508239
432 0.9502449165962931
433 0.9510709848882477
434 0.9542101198199829
435 0.952982162403804
436 0.9464220008542461
437 0.9557550324761312
438 0.9524355304711182
439 0.9475958600266433
440 0.9460896600531848
Train R2 - DI: 0.115
Val R2 - DI: 0.080
Test R2 - DI: 0.118
441 0.9458787717272303
442 0.9448562446460929
443 0.9486236584656554
444 0.949314858409239
445 0.9453413030579954
446 0.9476954588753348
447 0.9462017403281291
448 0.9460050113739505
449 0.9438665330196367
450 0.9502912635444313
Train R2 - DI: 0.103
Val R2 - DI: 0.070
Test R2 - DI: 0.106
451 0.9514637642863831
452 0.9437768820793399
453 0.9399695513496262
454 0.9481332205529709
455 0.9418144209837828
456 0.9405637423197428
457 0.9442823718952876
458 0.9381121047081485
459 0.9418973715929148
460 0.9352749297268502
Train R2 - DI: 0.120
Val R2 - DI: 0.085
Test R2 - DI: 0.120
461 0.9407595206759737
462 0.9402698977446471
463 0.9446664985790048
464 0.9356380492982899
465 0.9428610347932385
466 0.9475046778665221
467 0.9447998729657956
468 0.9327596498646616
469 0.9360610705122725
470 0.9350353750276736
Train R2 - DI: 0.119
Val R2 - DI: 0.084
Test R2 - DI: 0.119
471 0.94001979037425
472 0.9350053769285961
473 0.9374853904956558
474 0.9364887934004534
475 0.9356801591039131
476 0.9349136942603682
477 0.9329862151949209
478 0.930900867822777
479 0.9374624329228555
480 0.935838451949499
Train R2 - DI: 0.132
Val R2 - DI: 0.095
Test R2 - DI: 0.131
481 0.9368462552306472
482 0.9262946101072441
483 0.934038980032808
484 0.9302210803954832
485 0.9243973923840403
486 0.9324921407152675
487 0.9253511903533799
488 0.9365930050077405
489 0.927235197636389
490 0.9268136305193747
Train R2 - DI: 0.137
Val R2 - DI: 0.098
Test R2 - DI: 0.134
491 0.9247870847743045
492 0.9350409115514448
493 0.9279004650731241
494 0.9252564318291175
495 0.91764846805176
496 0.9212110731336806
497 0.928230005096791
498 0.9199483155349677
499 0.9207856058219855
500 0.9298082117111452
Train R2 - DI: 0.125
Val R2 - DI: 0.087
Test R2 - DI: 0.121
501 0.9269281255728882
502 0.9178939044261919
503 0.9185958545267796
504 0.9177945968498038
505 0.9150222901375064
506 0.9169223978100711
507 0.912961800038601
508 0.925700894265192
509 0.9170794489990426
510 0.9120904035892965
Train R2 - DI: 0.134
Val R2 - DI: 0.095
Test R2 - DI: 0.129
511 0.9096563727624954
512 0.9247682999111846
513 0.9057513545490935
514 0.9161008643420366
515 0.9061290743530438
516 0.913576832894356
517 0.918156483566462
518 0.910776319426875
519 0.9036234636887854
520 0.9080520840955891
Train R2 - DI: 0.154
Val R2 - DI: 0.111
Test R2 - DI: 0.147
521 0.9054312693602723
522 0.9067831239819953
523 0.9049540141577361
524 0.8998712671700344
525 0.9062963766863696
526 0.9103688069569167
527 0.909722688206635
528 0.8996363025839611
529 0.9008091057927805
530 0.9013998319598509
Train R2 - DI: 0.174
Val R2 - DI: 0.126
Test R2 - DI: 0.165
531 0.8950019136124614
532 0.9074335838304198
533 0.8896796686247685
534 0.9020148818210889
535 0.8951277704221801
536 0.8872745494261437
537 0.9058133731178912
538 0.8967770181676393
539 0.8884000282988326
540 0.8859603908326891
Train R2 - DI: 0.181
Val R2 - DI: 0.132
Test R2 - DI: 0.170
541 0.8966072620456791
542 0.8926648909045803
543 0.8864383134790647
544 0.8965941018955682
545 0.8925887697486468
546 0.8900734434845627
547 0.8865211658580329
548 0.8783162957023977
549 0.8877026465204026
550 0.8896210414107127
Train R2 - DI: 0.168
Val R2 - DI: 0.119
Test R2 - DI: 0.156
551 0.883230963830025
552 0.8809433858454441
553 0.8832772154961863
554 0.8789428817328586
555 0.8758476203487765
556 0.882061255234544
557 0.8839199118716743
558 0.8744439041315442
559 0.8784193187204313
560 0.8806419702840962
Train R2 - DI: 0.161
Val R2 - DI: 0.114
Test R2 - DI: 0.148
561 0.875585996634644
562 0.877280038958382
563 0.874533982687099
564 0.8699793783994558
565 0.8780447417689908
566 0.870639705401595
567 0.8797430787889761
568 0.8738508314642001
569 0.8765951948353894
570 0.872822685438245
Train R2 - DI: 0.216
Val R2 - DI: 0.158
Test R2 - DI: 0.201
571 0.8642764530301521
572 0.8654122907628296
573 0.8725006597870995
574 0.8691509462171986
575 0.8735431234041849
576 0.8637256844923915
577 0.8657220250816755
578 0.8634583257005206
579 0.8612394704613634
580 0.867335494316607
Train R2 - DI: 0.174
Val R2 - DI: 0.123
Test R2 - DI: 0.157
581 0.8651400054654768
582 0.8659703790927873
583 0.8602186910567745
584 0.8649778497689087
585 0.8683036834962906
586 0.8536475029897519
587 0.863876960909922
588 0.8610184534476222
589 0.8581862740191935
590 0.85811982962393
Train R2 - DI: 0.187
Val R2 - DI: 0.131
Test R2 - DI: 0.168
591 0.8584245644589906
592 0.8538083323013825
593 0.8592632814547494
594 0.8505191244532131
595 0.8605309541934707
596 0.8501681693138615
597 0.8533207735707683
598 0.8462086274205143
599 0.8561484198416432
600 0.8557646739012879
Train R2 - DI: 0.204
Val R2 - DI: 0.141
Test R2 - DI: 0.184
601 0.8458303732256736
602 0.8555449886561295
603 0.8504225030167556
604 0.8501395343025098
605 0.8471435698984344
606 0.8466326000015368
607 0.8394108089067602
608 0.8487752799919429
609 0.841628363482841
610 0.8401695647547321
Train R2 - DI: 0.207
Val R2 - DI: 0.142
Test R2 - DI: 0.181
611 0.8476523162216268
612 0.8450357688370571
613 0.8426495653754067
614 0.8472004641768753
615 0.8435453725972056
616 0.8352044616976092
617 0.8392701506614685
618 0.8454367199251729
619 0.835823797495989
620 0.8422396726505731
Train R2 - DI: 0.218
Val R2 - DI: 0.148
Test R2 - DI: 0.188
621 0.8355658454279746
622 0.835200933786276
623 0.8378807463526299
624 0.8310047912768566
625 0.8348067198175684
626 0.8237560436717071
627 0.8356066667050871
628 0.8421199014964497
629 0.8263467061476896
630 0.8246103582843658
Train R2 - DI: 0.231
Val R2 - DI: 0.157
Test R2 - DI: 0.196
631 0.8250049920065001
632 0.8253858638066117
633 0.8275160020397555
634 0.8227544406408904
635 0.8247656150530743
636 0.8185439599457608
637 0.8274447068945908
638 0.8250220508558348
639 0.8216344386018732
640 0.8233080411470065
Train R2 - DI: 0.196
Val R2 - DI: 0.123
Test R2 - DI: 0.157
641 0.8179939537492704
642 0.8248513483659341
643 0.8180713750982798
644 0.8233001939712032
645 0.8279419694322839
646 0.8185229408270996
647 0.812511061212068
648 0.8112114443146627
649 0.8111977252908932
650 0.8058575053368845
Train R2 - DI: 0.248
Val R2 - DI: 0.158
Test R2 - DI: 0.198
651 0.8061620475570788
652 0.8047925467559514
653 0.805625831696295
654 0.8026579541972034
655 0.805164967258344
656 0.7978240803151148
657 0.8096960256603883
658 0.803724006085413
659 0.8001917488686073
660 0.7997888384754085
Train R2 - DI: 0.230
Val R2 - DI: 0.133
Test R2 - DI: 0.173
661 0.7890139677618567
662 0.8021923847523215
663 0.7915342396305454
664 0.7911704596225506
665 0.795442162534242
666 0.7926172456006423
667 0.7950857976004214
668 0.7799373995445963
669 0.7837711522228828
670 0.7880402056547049
Train R2 - DI: 0.226
Val R2 - DI: 0.118
Test R2 - DI: 0.161
671 0.7826487890708403
672 0.7784622655119947
673 0.7826546336160338
674 0.7800509965975225
675 0.780465677433971
676 0.7762684540722959
677 0.7714956897988542
678 0.7771718870781655
679 0.7703825849358753
680 0.76763779134306
Train R2 - DI: 0.216
Val R2 - DI: 0.098
Test R2 - DI: 0.133
681 0.7714178367327619
682 0.7682254692559601
683 0.765466636825206
684 0.7589546272404305
685 0.7651015448313887
686 0.7617511913340579
687 0.7530535922041931
688 0.7564824769573827
689 0.7573749464472562
690 0.7540757270269497
Train R2 - DI: 0.197
Val R2 - DI: 0.067
Test R2 - DI: 0.103
691 0.7561358650952684
692 0.7454222753056489
693 0.7437764255803972
694 0.7482182188700605
695 0.7407850543657939
696 0.7478169581368833
697 0.7383262706486555
698 0.7429158389781966
699 0.755873131111104
700 0.74003323961757
Train R2 - DI: 0.322
Val R2 - DI: 0.159
Test R2 - DI: 0.203
701 0.7316365344977294
702 0.7325726049348018
703 0.7298955082038825
704 0.7306756100774239
705 0.725395179563953
706 0.7347337027177161
707 0.7223874826585093
708 0.7158044083144075
709 0.7152732265465576
710 0.7165116721156678
Train R2 - DI: 0.370
Val R2 - DI: 0.176
Test R2 - DI: 0.223
711 0.7171796368868975
712 0.7179036147705543
713 0.7069995141371177
714 0.7143625693509228
715 0.70339092178584
716 0.7118233555961253
717 0.7065564162842262
718 0.7037365018253258
719 0.6984246931622959
720 0.7011308179106763
Train R2 - DI: 0.388
Val R2 - DI: 0.177
Test R2 - DI: 0.222
721 0.6988712697473478
722 0.6920485090183955
723 0.6903402860446642
724 0.692461534042085
725 0.6946712662242219
726 0.6935779028041389
727 0.6782274176142976
728 0.6780876354931931
729 0.6836534688122383
730 0.6752115445752298
Train R2 - DI: 0.383
Val R2 - DI: 0.156
Test R2 - DI: 0.195
731 0.6772961385361183
732 0.6728663325309754
733 0.6683585972768858
734 0.6674473120747502
735 0.6796663369756446
736 0.6675581652631042
737 0.64841432058683
738 0.663592482211342
739 0.6559637677712252
740 0.6589152029338277
Train R2 - DI: 0.321
Val R2 - DI: 0.080
Test R2 - DI: 0.119
741 0.6517230984557913
742 0.6530642735488098
743 0.642869979121779
744 0.6595362821787489
745 0.6466271623915669
746 0.6522090714892179
747 0.6492759743899
748 0.6450162733754804
749 0.6485202711542875
750 0.6386487322041638
Train R2 - DI: 0.412
Val R2 - DI: 0.139
Test R2 - DI: 0.187
751 0.635933506360618
752 0.6284299163835451
753 0.6289887241565199
754 0.6326113383402534
755 0.6324851803027601
756 0.6244744662315614
757 0.6251912674596233
758 0.6214438802025224
759 0.6113858060597519
760 0.6184795844512174
Train R2 - DI: 0.433
Val R2 - DI: 0.137
Test R2 - DI: 0.184
761 0.6185004998278875
762 0.6067403570725499
763 0.6090398688470163
764 0.6131632225060548
765 0.6086677940942908
766 0.6090049847907063
767 0.6028752184683277
768 0.5990254816188607
769 0.6010455707922632
770 0.6059616574249814
Train R2 - DI: 0.472
Val R2 - DI: 0.147
Test R2 - DI: 0.206
771 0.5956995666667979
772 0.6045900969095127
773 0.5979286184447641
774 0.5961384365421897
775 0.5806127191230815
776 0.5889314157561162
777 0.5969976033361155
778 0.5959750014821261
779 0.5895968111612464
780 0.5851198667052826
Train R2 - DI: 0.503
Val R2 - DI: 0.159
Test R2 - DI: 0.213
781 0.5899750296146639
782 0.5763101837968314
783 0.5809818077899221
784 0.5822776403478397
785 0.5742205597593792
786 0.5717548638261775
787 0.5790698278762106
788 0.559487180256929
789 0.5667453876105688
790 0.5592035793702662
Train R2 - DI: 0.533
Val R2 - DI: 0.166
Test R2 - DI: 0.215
791 0.5512146042880192
792 0.5641226490979554
793 0.5618313734676675
794 0.566859353336382
795 0.5701493793490967
796 0.5583614301083336
797 0.5524081319890997
798 0.5527262753055942
799 0.5470101979043749
800 0.5460756237788867
Train R2 - DI: 0.567
Val R2 - DI: 0.171
Test R2 - DI: 0.235
0.1765251326266406
Test R2 - DI: 0.235
Test R2 - DI: 0.222

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 14710793: <testjob> in cluster <dcc> Done

Job <testjob> was submitted from host <n-62-30-1> by user <s174503> in cluster <dcc> at Wed Nov  9 19:26:21 2022
Job was executed on host(s) <n-62-20-15>, in queue <gpuv100>, as user <s174503> in cluster <dcc> at Wed Nov  9 19:28:12 2022
</zhome/fd/6/127382> was used as the home directory.
</zhome/fd/6/127382/Desktop/MasterThesis/Master-thesis> was used as the working directory.
Started at Wed Nov  9 19:28:12 2022
Terminated at Wed Nov  9 23:41:11 2022
Results reported at Wed Nov  9 23:41:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J testjob
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 10:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -o outputs/gpu_%J.out
#BSUB -e outputs/errors/gpu_%J.err

nvidia-smi
module load cuda/11.6

/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery

source $HOME/miniconda3/bin/activate
source venv_1/bin/activate

#python3 main.py Deep_google 128 1e-6 10 800 2_4_test3 7
python3 main.py Deep_google 128 1e-6 20 800 shuffle_test4 99
#python3 main.py CNN_simple 128 1e-6 50 100 shufflev1 99


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   13346.43 sec.
    Max Memory :                                 2270 MB
    Average Memory :                             2222.10 MB
    Total Requested Memory :                     5120.00 MB
    Delta Memory :                               2850.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   15179 sec.
    Turnaround time :                            15290 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/errors/gpu_14710793.err> for stderr output of this job.

