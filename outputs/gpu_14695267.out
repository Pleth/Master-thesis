Tue Nov  8 18:50:00 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:37:00.0 Off |                    0 |
| N/A   32C    P0    25W / 250W |      0MiB / 16384MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "Tesla V100-PCIE-16GB"
  CUDA Driver Version / Runtime Version          11.7 / 11.6
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 16161 MBytes (16945709056 bytes)
  (080) Multiprocessors, (064) CUDA Cores/MP:    5120 CUDA Cores
  GPU Max Clock rate:                            1380 MHz (1.38 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 7 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 55 / 0
  Compute Mode:
     < Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.7, CUDA Runtime Version = 11.6, NumDevs = 1
Result = PASS
Deep_google
batch_size =  128 lr =  1e-06 wd =  10.0
5276 1164 1140
cuda:0
1 3.9319452870696487
2 3.5162830262404667
3 3.2464248056751566
4 3.0179263654308306
5 2.812815409885201
6 2.6491473925845743
7 2.506028346350195
8 2.4004933425564943
9 2.2727604279290374
10 2.2064609706537395
Train R2 - DI: -1.174
Val R2 - DI: -0.871
Test R2 - DI: -0.958
11 2.124094936863955
12 2.047381111308424
13 2.0033836140607324
14 1.9222207320649305
15 1.8848161167769473
16 1.8256674174380356
17 1.7965199827153724
18 1.7662668186575288
19 1.736667344206838
20 1.694911303711805
Train R2 - DI: -0.675
Val R2 - DI: -0.435
Test R2 - DI: -0.556
21 1.6495050070772033
22 1.6207845672863375
23 1.577469362464251
24 1.5479099051892713
25 1.5295250906557454
26 1.4984333829684544
27 1.4754566980004762
28 1.4474847745136206
29 1.4369365399854486
30 1.4130532784024543
Train R2 - DI: -0.413
Val R2 - DI: -0.230
Test R2 - DI: -0.352
31 1.3947884935244546
32 1.3848384662140854
33 1.3489406482119557
34 1.3455192263692144
35 1.3232547764619071
36 1.313057523138872
37 1.3152549180051791
38 1.2819387643422206
39 1.270078420277524
40 1.2549447047611002
Train R2 - DI: -0.265
Val R2 - DI: -0.122
Test R2 - DI: -0.232
41 1.2380556826613183
42 1.226329537799089
43 1.224436620539838
44 1.2296962331333696
45 1.2050066727232627
46 1.1951276031382794
47 1.1942804894544936
48 1.1798541042459472
49 1.1784575163549866
50 1.1767469704196343
Train R2 - DI: -0.177
Val R2 - DI: -0.057
Test R2 - DI: -0.168
51 1.151226786251227
52 1.1422790498603375
53 1.1323471807276688
54 1.1272264155047331
55 1.1309867394160285
56 1.1151105523380571
57 1.1231606125921982
58 1.11038236260143
59 1.09520698764091
60 1.0840092350625015
Train R2 - DI: -0.104
Val R2 - DI: -0.011
Test R2 - DI: -0.105
61 1.0849885769736325
62 1.0738722140179882
63 1.081159956171442
64 1.0733736537459042
65 1.0651373007787368
66 1.0688685051322977
67 1.0489009532899545
68 1.0435483920203636
69 1.0335544561056407
70 1.0491363884735685
Train R2 - DI: -0.043
Val R2 - DI: 0.027
Test R2 - DI: -0.053
71 1.0459898508706718
72 1.0223073623142431
73 1.0124905068735177
74 1.0312130029134627
75 1.0107506827209103
76 1.0029202110393198
77 1.015567906839184
78 1.004841261239012
79 1.006349879019725
80 1.0022307870241618
Train R2 - DI: -0.012
Val R2 - DI: 0.050
Test R2 - DI: -0.028
81 0.99119735450976
82 0.994034658154364
83 0.9865165678184081
84 0.9860069736375151
85 0.9875796817305235
86 0.9865275148282546
87 0.9837072501587452
88 0.9794204259705055
89 0.969121163952432
90 0.9628416803228395
Train R2 - DI: 0.036
Val R2 - DI: 0.073
Test R2 - DI: 0.018
91 0.9604154478156991
92 0.9546023017082186
93 0.9682691583496047
94 0.9580128586048244
95 0.9487485792530225
96 0.9555166723874593
97 0.9523851801899006
98 0.9491702945418571
99 0.9537339831410799
100 0.9406069433083581
Train R2 - DI: 0.037
Val R2 - DI: 0.078
Test R2 - DI: 0.014
101 0.9471148514584938
102 0.9412623115160684
103 0.9377330728694289
104 0.9299024985178209
105 0.9236989808498322
106 0.9156040543403654
107 0.9345436328690191
108 0.9319351317079977
109 0.9272498318966452
110 0.9396681396955789
Train R2 - DI: 0.059
Val R2 - DI: 0.089
Test R2 - DI: 0.037
111 0.9211154417434907
112 0.9209306667572265
113 0.9129011087385066
114 0.9286631153242618
115 0.9169713615286612
116 0.912157886402457
117 0.9134768610926086
118 0.9138952212138461
119 0.9081626981383838
120 0.9079067181510578
Train R2 - DI: 0.073
Val R2 - DI: 0.098
Test R2 - DI: 0.051
121 0.9094545499586173
122 0.8979376409883477
123 0.897826074198216
124 0.8920075921419446
125 0.8986640788552615
126 0.8921106532272559
127 0.8907474128923424
128 0.8961105485862634
129 0.8935475259499626
130 0.8830786802445152
Train R2 - DI: 0.089
Val R2 - DI: 0.106
Test R2 - DI: 0.065
131 0.8878334494952996
132 0.8875579590866112
133 0.8810932171715309
134 0.8766820029474913
135 0.869810889126949
136 0.8686443897609551
137 0.873235091013471
138 0.8850734920733078
139 0.8795880678930998
140 0.8765237128038674
Train R2 - DI: 0.091
Val R2 - DI: 0.108
Test R2 - DI: 0.067
141 0.8768595559656666
142 0.874301113035753
143 0.8719802153119542
144 0.8665566161512154
145 0.87017737418255
146 0.8701265265853049
147 0.8667053962133435
148 0.8617325770845912
149 0.8623970069154996
150 0.8593660098662242
Train R2 - DI: 0.120
Val R2 - DI: 0.119
Test R2 - DI: 0.093
151 0.8677217068321511
152 0.8595868036365581
153 0.8597662193111798
154 0.8612131448384936
155 0.8592915242146687
156 0.8497423784944305
157 0.852700384482007
158 0.8528550433064158
159 0.8501434957014059
160 0.854598446494255
Train R2 - DI: 0.134
Val R2 - DI: 0.125
Test R2 - DI: 0.109
161 0.851656881718133
162 0.842625507448007
163 0.8472855635851599
164 0.8445449053472963
165 0.8433746776407284
166 0.8411665754484534
167 0.8448376118730107
168 0.8457619525701192
169 0.8422572215548784
170 0.8466569234061367
Train R2 - DI: 0.146
Val R2 - DI: 0.130
Test R2 - DI: 0.115
171 0.8356903770640549
172 0.8465592660535186
173 0.8428489943631586
174 0.8318090872659748
175 0.8376934405436021
176 0.8276228145092522
177 0.8352476288822224
178 0.8328357073418383
179 0.8410809659162555
180 0.8305404699146973
Train R2 - DI: 0.147
Val R2 - DI: 0.133
Test R2 - DI: 0.116
181 0.8392203287973469
182 0.8405571492717879
183 0.8358453380239109
184 0.8295467281721143
185 0.8269618502885125
186 0.8208709892176425
187 0.8334981610686423
188 0.8247435642879419
189 0.8263264643007197
190 0.8255119107725767
Train R2 - DI: 0.159
Val R2 - DI: 0.133
Test R2 - DI: 0.129
191 0.8237736771918319
192 0.8239912758097674
193 0.8196490532164324
194 0.8232187245089145
195 0.8163785883384369
196 0.8205144004536181
197 0.8173523973207568
198 0.8148018800914062
199 0.823012093868646
200 0.8213981672884209
Train R2 - DI: 0.159
Val R2 - DI: 0.136
Test R2 - DI: 0.129
201 0.8141575465155335
202 0.8163033650624563
203 0.8105166272018063
204 0.808519510087685
205 0.8126873129059456
206 0.8197848615183624
207 0.8223588705243623
208 0.8175311385907397
209 0.8079437469333478
210 0.8113725412244414
Train R2 - DI: 0.167
Val R2 - DI: 0.138
Test R2 - DI: 0.133
211 0.8093754481510107
212 0.81093457720784
213 0.8044607159402716
214 0.8148923712846815
215 0.8119534438898204
216 0.8061119636592764
217 0.8050468048875851
218 0.8035748304066286
219 0.8122220208375539
220 0.8056334148671611
Train R2 - DI: 0.171
Val R2 - DI: 0.141
Test R2 - DI: 0.138
221 0.7997390378416263
222 0.8041319718317519
223 0.8041653249912681
224 0.8046217868055151
225 0.7991226259915553
226 0.8078767087895189
227 0.7986390191646486
228 0.8066492618892661
229 0.8030424838358927
230 0.8044096853264902
Train R2 - DI: 0.164
Val R2 - DI: 0.142
Test R2 - DI: 0.131
231 0.8006189781847644
232 0.8001854609051285
233 0.7980010856092654
234 0.8004407012345124
235 0.7924662495400527
236 0.7975321948031208
237 0.795761055255858
238 0.7918648464694179
239 0.792696928869512
240 0.802925287231159
Train R2 - DI: 0.183
Val R2 - DI: 0.146
Test R2 - DI: 0.148
241 0.7968975517494918
242 0.7968243297706327
243 0.7934818763096645
244 0.7947917053245793
245 0.7862251836572116
246 0.7899301933736129
247 0.7951061490180368
248 0.797424188023539
249 0.7946445373895947
250 0.7898911242235601
Train R2 - DI: 0.180
Val R2 - DI: 0.149
Test R2 - DI: 0.146
251 0.7875543010108302
252 0.7880929099781392
253 0.7885322579838635
254 0.7907334431000421
255 0.7894227398083552
256 0.7835748290545657
257 0.7895201225006011
258 0.7843060333951122
259 0.7884008485408693
260 0.7881170706463366
Train R2 - DI: 0.177
Val R2 - DI: 0.152
Test R2 - DI: 0.141
261 0.7912822651356979
262 0.7876165430594612
263 0.7873416935701638
264 0.783957721248913
265 0.7797045249483457
266 0.7866950903181057
267 0.7830319366643066
268 0.7801380302076362
269 0.7776005318257011
270 0.7796109166897274
Train R2 - DI: 0.185
Val R2 - DI: 0.154
Test R2 - DI: 0.150
271 0.77620081561727
272 0.7802876273821121
273 0.7832810834920072
274 0.7829143030341599
275 0.777971139272295
276 0.7800635245372347
277 0.775098503675309
278 0.779620109497371
279 0.7759202419581785
280 0.7715335250623846
Train R2 - DI: 0.193
Val R2 - DI: 0.155
Test R2 - DI: 0.158
281 0.7846985521236995
282 0.7765328788097561
283 0.7758269837582265
284 0.7749654391753664
285 0.7752791189216501
286 0.7685697330409058
287 0.7756522970727395
288 0.7753269238124931
289 0.769734236803626
290 0.7764520672255163
Train R2 - DI: 0.190
Val R2 - DI: 0.158
Test R2 - DI: 0.152
291 0.7773236715947253
292 0.7814090274517241
293 0.7699975591884408
294 0.7734749184312741
295 0.7673702602860059
296 0.7793908890130576
297 0.7714785232609018
298 0.7653147656416875
299 0.7730614137161492
300 0.7743789117565835
Train R2 - DI: 0.201
Val R2 - DI: 0.160
Test R2 - DI: 0.163
301 0.7681704835515749
302 0.7744735360281136
303 0.7682684437174794
304 0.7649462561068705
305 0.7702525951945484
306 0.7697883454392226
307 0.769144133693617
308 0.7679599835350263
309 0.7656854188198208
310 0.7681753355233031
Train R2 - DI: 0.205
Val R2 - DI: 0.163
Test R2 - DI: 0.166
311 0.7657648858651688
312 0.766466348436947
313 0.7616653917773915
314 0.7650114868607278
315 0.7681523302995047
316 0.7636088291924501
317 0.7621100916385289
318 0.766015254610682
319 0.7657512534830586
320 0.7668798428489187
Train R2 - DI: 0.205
Val R2 - DI: 0.162
Test R2 - DI: 0.160
321 0.7656596607561813
322 0.7614151177033951
323 0.7597863357387048
324 0.763246046855108
325 0.7635012388319748
326 0.7593029757355813
327 0.7579412458519578
328 0.7621375558681792
329 0.757401745729685
330 0.758028176673169
Train R2 - DI: 0.208
Val R2 - DI: 0.166
Test R2 - DI: 0.164
331 0.762357439481462
332 0.7610676895044716
333 0.7584075503633093
334 0.76131213929185
335 0.7613183276684018
336 0.7579624586434325
337 0.7570881030611959
338 0.7604849798558244
339 0.7539791345957828
340 0.7582474227110665
Train R2 - DI: 0.216
Val R2 - DI: 0.171
Test R2 - DI: 0.171
341 0.761281278252692
342 0.7614786351965267
343 0.7536191810840364
344 0.7556282159412694
345 0.7588176316072581
346 0.7556771035895734
347 0.7499205146529984
348 0.7614207221668177
349 0.7517263793963388
350 0.7574868687768159
Train R2 - DI: 0.220
Val R2 - DI: 0.172
Test R2 - DI: 0.175
351 0.7529457377790952
352 0.7483996319626207
353 0.75468260479118
354 0.7585147382907563
355 0.7549530912566311
356 0.7532510901148162
357 0.7527251028942284
358 0.7552602231231398
359 0.749710325357858
360 0.7537794036337424
Train R2 - DI: 0.216
Val R2 - DI: 0.174
Test R2 - DI: 0.165
361 0.752800438691487
362 0.7508203842768261
363 0.754787885754103
364 0.7522005367405583
365 0.7474166566535684
366 0.7497454587937847
367 0.7493129190258043
368 0.7513821946119521
369 0.7494914331519306
370 0.7534000799003381
Train R2 - DI: 0.221
Val R2 - DI: 0.177
Test R2 - DI: 0.164
371 0.7473883779325478
372 0.7512771607439477
373 0.7486469017636875
374 0.7481525595934667
375 0.7477865614974201
376 0.7416785947746901
377 0.744306684353751
378 0.744029236074828
379 0.7459408029902604
380 0.7435287827339201
Train R2 - DI: 0.230
Val R2 - DI: 0.180
Test R2 - DI: 0.171
381 0.7477053352790497
382 0.7437597212690219
383 0.7456477390626238
384 0.7413181700066602
385 0.7406081843773825
386 0.7469376007474852
387 0.7387573575322786
388 0.7428026629090762
389 0.7436627653442249
390 0.7390385679533483
Train R2 - DI: 0.238
Val R2 - DI: 0.180
Test R2 - DI: 0.182
391 0.7365214088091442
392 0.7454097910845614
393 0.7423622735618551
394 0.7345941499655133
395 0.7411589158855667
396 0.7378825145837843
397 0.7375661927791506
398 0.7431308860757118
399 0.7387535981014879
400 0.7389983141214401
Train R2 - DI: 0.223
Val R2 - DI: 0.183
Test R2 - DI: 0.153
0.18305649177851602
Test R2 - DI: 0.153
Test R2 - DI: 0.153
Deep_google
batch_size =  128 lr =  1e-06 wd =  10.0
5580 1000 1000
cuda:0
1 3.8349950824587147
2 3.490115921642618
3 3.2351824493818384
4 2.974982967000708
5 2.8329860830819733
6 2.708343097385967
7 2.5815070482992355
8 2.4595019048260105
9 2.3442920599359764
10 2.2672060945982575
Train R2 - DI: -1.098
Val R2 - DI: -1.058
Test R2 - DI: -0.965
11 2.195732658909213
12 2.1258206948584553
13 2.073871444544912
14 2.0065271401490787
15 1.936749056505046
16 1.9019399784799118
17 1.8373864185852817
18 1.8216600583018367
19 1.768751903161353
20 1.7429520941977006
Train R2 - DI: -0.626
Val R2 - DI: -0.588
Test R2 - DI: -0.516
21 1.7110418008647084
22 1.6774599252208586
23 1.6501972116449828
24 1.6442760547002158
25 1.6136941685898758
26 1.5838030240014462
27 1.5629206780464417
28 1.5363749435725604
29 1.5198993052205731
30 1.4902857653129058
Train R2 - DI: -0.382
Val R2 - DI: -0.347
Test R2 - DI: -0.290
31 1.4691718487756653
32 1.4599100768352495
33 1.4581991033314805
34 1.433127351302827
35 1.398793470047708
36 1.3992035378691972
37 1.3824188554586048
38 1.3632033072064855
39 1.3549695290972255
40 1.326919505416706
Train R2 - DI: -0.240
Val R2 - DI: -0.206
Test R2 - DI: -0.159
41 1.3365586550859567
42 1.3300232466831001
43 1.3143204909498973
44 1.3078036875707701
45 1.2948527768521325
46 1.2765687633158913
47 1.269991163797276
48 1.2555722828834288
49 1.269617801926042
50 1.2500314441633054
Train R2 - DI: -0.154
Val R2 - DI: -0.122
Test R2 - DI: -0.082
51 1.2327931967260162
52 1.231366362110261
53 1.234228485203131
54 1.224222775941254
55 1.2139754880713733
56 1.207788161821263
57 1.1961842201943893
58 1.1892394449121209
59 1.1806741224822177
60 1.1834209087501717
Train R2 - DI: -0.077
Val R2 - DI: -0.046
Test R2 - DI: -0.010
61 1.1700088603522187
62 1.158126663648954
63 1.1472918391654996
64 1.1531458297510728
65 1.1499323430454431
66 1.1418801628133302
67 1.142535952000635
68 1.1362681754601045
69 1.1199095835822457
70 1.1261870885835326
Train R2 - DI: -0.029
Val R2 - DI: 0.001
Test R2 - DI: 0.033
71 1.119657806427248
72 1.112348128817842
73 1.104655932781944
74 1.098825482655597
75 1.1035444555316776
76 1.0986397447551877
77 1.0864263284590936
78 1.087366142324222
79 1.0928777844247852
80 1.0751821355580429
Train R2 - DI: 0.009
Val R2 - DI: 0.037
Test R2 - DI: 0.068
81 1.0670445254626668
82 1.0679622580928188
83 1.0677321482730169
84 1.0619416086477191
85 1.0575888648255325
86 1.049327744634348
87 1.0632694184566485
88 1.0455287644512765
89 1.054706362156885
90 1.0449263980739005
Train R2 - DI: 0.031
Val R2 - DI: 0.058
Test R2 - DI: 0.087
91 1.0303799725775222
92 1.032261412758981
93 1.0297517224024701
94 1.0326840816432856
95 1.0346659550957356
96 1.026720970249518
97 1.0320335633438549
98 1.0109693482785242
99 1.0174466554409287
100 1.0125675158688672
Train R2 - DI: 0.065
Val R2 - DI: 0.091
Test R2 - DI: 0.118
101 1.0083823885968937
102 1.0039237746201108
103 1.0036568339153003
104 1.0040011191453557
105 1.0038793548033655
106 0.9998469612931693
107 0.9995232314619112
108 0.9916497862039928
109 0.99783759655491
110 0.9865171549140767
Train R2 - DI: 0.085
Val R2 - DI: 0.111
Test R2 - DI: 0.136
111 0.9837963707558143
112 0.9881196965880719
113 0.9704635241980194
114 0.9879495477163663
115 0.9866634766260783
116 0.9818272526546191
117 0.9746914187639845
118 0.9772234574013714
119 0.9718466602773222
120 0.9671352770166158
Train R2 - DI: 0.106
Val R2 - DI: 0.132
Test R2 - DI: 0.156
121 0.966588820650586
122 0.9679925933106398
123 0.9619288758137747
124 0.9612686170044765
125 0.9536440241721369
126 0.9512985540974525
127 0.9561171074494667
128 0.9488717569672506
129 0.9556157540249568
130 0.9460357146878396
Train R2 - DI: 0.118
Val R2 - DI: 0.141
Test R2 - DI: 0.166
131 0.9419842520067768
132 0.9478796792713972
133 0.9461287694165357
134 0.9505952974374149
135 0.9425216631222797
136 0.9434240979960316
137 0.9447625830609311
138 0.9419432763984981
139 0.932931579740244
140 0.9407783268173109
Train R2 - DI: 0.124
Val R2 - DI: 0.147
Test R2 - DI: 0.172
141 0.9365635289086236
142 0.932120222259166
143 0.9389128094505665
144 0.9301136581701189
145 0.9343068415546075
146 0.9242488642319984
147 0.9273721788091899
148 0.9181623258898335
149 0.9252218634851517
150 0.9270115278955001
Train R2 - DI: 0.132
Val R2 - DI: 0.155
Test R2 - DI: 0.179
151 0.924573254328902
152 0.9199849436787294
153 0.9299108929104275
154 0.9202826559757247
155 0.914497787294422
156 0.9219255465333179
157 0.913059966025814
158 0.911614174142106
159 0.9122529980529593
160 0.9200627644002224
Train R2 - DI: 0.148
Val R2 - DI: 0.172
Test R2 - DI: 0.195
161 0.916276204329665
162 0.9154317056406356
163 0.9159625646461296
164 0.9098760598449297
165 0.9026687592161172
166 0.906661444838329
167 0.9082333852313326
168 0.8992012575108518
169 0.9124124729077876
170 0.9033825030890844
Train R2 - DI: 0.160
Val R2 - DI: 0.185
Test R2 - DI: 0.206
171 0.9019809843818773
172 0.9039878334623084
173 0.9048987515938325
174 0.906840259242656
175 0.8923330431770681
176 0.9023414261452186
177 0.8928496573560981
178 0.8977792830022859
179 0.8965824280161157
180 0.899444108111884
Train R2 - DI: 0.160
Val R2 - DI: 0.184
Test R2 - DI: 0.206
181 0.8901895304734562
182 0.8913374247944056
183 0.8971361608060885
184 0.8933681558537226
185 0.8831756888324642
186 0.8949433123339035
187 0.8861446739524923
188 0.8892817616035434
189 0.8849386257937305
190 0.8861099473891719
Train R2 - DI: 0.165
Val R2 - DI: 0.190
Test R2 - DI: 0.211
191 0.8890658017127745
192 0.8817321447488655
193 0.8764942746863142
194 0.8856661332123595
195 0.878022805593347
196 0.8811546028728553
197 0.8817370046851456
198 0.8795103036801875
199 0.8841611622909491
200 0.8819295890442359
Train R2 - DI: 0.170
Val R2 - DI: 0.195
Test R2 - DI: 0.216
201 0.8798065034292077
202 0.8853621638376653
203 0.8891359070723202
204 0.8763357495748868
205 0.8802246947015058
206 0.8850510300273964
207 0.8782018000934286
208 0.8793640071773188
209 0.869127604739213
210 0.8749514022608385
Train R2 - DI: 0.177
Val R2 - DI: 0.202
Test R2 - DI: 0.222
211 0.879013114633526
212 0.8762603963147783
213 0.8763958182813446
214 0.8725826359136984
215 0.8766317472662977
216 0.8679336521360609
217 0.87394740363603
218 0.863288519587568
219 0.8710991545390058
220 0.8725706127382094
Train R2 - DI: 0.179
Val R2 - DI: 0.202
Test R2 - DI: 0.222
221 0.8711520971790436
222 0.8652919604359561
223 0.8666756192415845
224 0.8678640333127805
225 0.8643444027524695
226 0.8700190634710387
227 0.8705676488124342
228 0.8674854689601502
229 0.870327865949241
230 0.8620794325746516
Train R2 - DI: 0.179
Val R2 - DI: 0.203
Test R2 - DI: 0.224
231 0.8695384382774326
232 0.8634586787992908
233 0.8619848934980276
234 0.8667244489474963
235 0.8609343069001338
236 0.8616840389039782
237 0.8631792008663164
238 0.8633401783563758
239 0.8563747660660829
240 0.8590141286986703
Train R2 - DI: 0.190
Val R2 - DI: 0.214
Test R2 - DI: 0.234
241 0.8593946576973016
242 0.861837567351625
243 0.8584799984022707
244 0.8578827626816261
245 0.8639190314063889
246 0.8578867306418744
247 0.8588954734545882
248 0.8590002440209884
249 0.8575885250149662
250 0.8556998333623332
Train R2 - DI: 0.184
Val R2 - DI: 0.208
Test R2 - DI: 0.228
251 0.8557969987178788
252 0.8542040962472184
253 0.8575238503008333
254 0.8563380157221175
255 0.8584470210536834
256 0.8509047147620963
257 0.8538865779035835
258 0.8585238844690357
259 0.8554646428340652
260 0.8538620983400652
Train R2 - DI: 0.198
Val R2 - DI: 0.222
Test R2 - DI: 0.241
261 0.8501878463666499
262 0.8537923641529562
263 0.857907739762337
264 0.8486977598573144
265 0.8506430795115809
266 0.8493797479137297
267 0.8499828431341383
268 0.8489952513393962
269 0.8513171506611678
270 0.8487747481219657
Train R2 - DI: 0.201
Val R2 - DI: 0.225
Test R2 - DI: 0.244
271 0.8532277385821052
272 0.8458896716863024
273 0.848573338344533
274 0.8459134486413771
275 0.8510068995123695
276 0.8504053808882245
277 0.8499021837788243
278 0.8455532691812002
279 0.843509475219207
280 0.8469890141572576
Train R2 - DI: 0.202
Val R2 - DI: 0.225
Test R2 - DI: 0.244
281 0.846337542525329
282 0.8476381397589133
283 0.848756769566553
284 0.835892416926695
285 0.8429962900377089
286 0.8494297166024485
287 0.8440919101024614
288 0.8455143478608901
289 0.8376354843484886
290 0.8486027422771659
Train R2 - DI: 0.202
Val R2 - DI: 0.225
Test R2 - DI: 0.244
291 0.8396593669409393
292 0.841639412517616
293 0.8402219304901725
294 0.8401678101563539
295 0.8385767067632367
296 0.8386249907982393
297 0.8435326664251238
298 0.8414723803920131
299 0.8334869812893612
300 0.8378228646025435
Train R2 - DI: 0.212
Val R2 - DI: 0.234
Test R2 - DI: 0.252
301 0.8393935074515667
302 0.8389468679718647
303 0.8341919804559387
304 0.8373822081473565
305 0.8438463273441492
306 0.8308034914368797
307 0.8359784468527763
308 0.8432170262046185
309 0.8384961362807981
310 0.8365012086420504
Train R2 - DI: 0.206
Val R2 - DI: 0.227
Test R2 - DI: 0.246
311 0.8348233935653523
312 0.837259688898654
313 0.8331807809918584
314 0.8425446483823988
315 0.8382108807991056
316 0.8344471512729549
317 0.8336925835165072
318 0.8344900109434641
319 0.8341607702248413
320 0.8372115431293364
Train R2 - DI: 0.206
Val R2 - DI: 0.227
Test R2 - DI: 0.245
321 0.8264637838982339
322 0.8338155465314038
323 0.8370459857380091
324 0.8367686319949379
325 0.8354866505523736
326 0.8295484074554991
327 0.828545806271201
328 0.8348348847426821
329 0.8331342142969904
330 0.8298979896798356
Train R2 - DI: 0.216
Val R2 - DI: 0.236
Test R2 - DI: 0.254
331 0.8274886795696819
332 0.831047914233259
333 0.8290002782285
334 0.8244578957984952
335 0.826852085342544
336 0.8278036505517994
337 0.8281499235433489
338 0.8327940444365197
339 0.8325094640468611
340 0.8267049109636669
Train R2 - DI: 0.212
Val R2 - DI: 0.231
Test R2 - DI: 0.249
341 0.8278017027403719
342 0.8249435279958992
343 0.8318973280195694
344 0.8249091996941516
345 0.8212983617218592
346 0.8296804843837642
347 0.82321210450169
348 0.8206723668669287
349 0.8266190368214815
350 0.825661359380223
Train R2 - DI: 0.220
Val R2 - DI: 0.238
Test R2 - DI: 0.256
351 0.8290279819973908
352 0.8202052457358248
353 0.8180310956038882
354 0.8245393438578507
355 0.8335725022473216
356 0.8189800313723985
357 0.8208772321328467
358 0.8254547832687269
359 0.817219528630643
360 0.8246127686192912
Train R2 - DI: 0.211
Val R2 - DI: 0.229
Test R2 - DI: 0.247
361 0.822938754738018
362 0.8205940700773697
363 0.8215131008069575
364 0.8228298340647024
365 0.8145050538056213
366 0.818444185658595
367 0.8199649481790467
368 0.8175826249584075
369 0.8180146975329272
370 0.8128527572932637
Train R2 - DI: 0.235
Val R2 - DI: 0.253
Test R2 - DI: 0.268
371 0.8168276088639399
372 0.8119810508570791
373 0.8186652100214394
374 0.8182849022222676
375 0.8101666514591505
376 0.8152083366147933
377 0.8166781563058122
378 0.8129341427997876
379 0.8163911824585289
380 0.8159660624346853
Train R2 - DI: 0.234
Val R2 - DI: 0.252
Test R2 - DI: 0.267
381 0.8171109784888537
382 0.8155302971494668
383 0.8086995185489723
384 0.813564753190591
385 0.8212750783103341
386 0.8177224436113911
387 0.8161263432981293
388 0.8106042653856311
389 0.8131923679809844
390 0.8114898412458358
Train R2 - DI: 0.225
Val R2 - DI: 0.240
Test R2 - DI: 0.257
391 0.8103505600310569
392 0.8121924397765949
393 0.8097941696857466
394 0.8115930279950514
395 0.8075297248406222
396 0.8087128167938588
397 0.8120696013119059
398 0.8157219122387602
399 0.8102461306852252
400 0.8113752331784977
Train R2 - DI: 0.234
Val R2 - DI: 0.250
Test R2 - DI: 0.265
0.2528559873834435
Test R2 - DI: 0.265
Test R2 - DI: 0.268

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 14695267: <testjob> in cluster <dcc> Done

Job <testjob> was submitted from host <n-62-27-20> by user <s174503> in cluster <dcc> at Tue Nov  8 18:49:59 2022
Job was executed on host(s) <n-62-20-7>, in queue <gpuv100>, as user <s174503> in cluster <dcc> at Tue Nov  8 18:49:59 2022
</zhome/fd/6/127382> was used as the home directory.
</zhome/fd/6/127382/Desktop/MasterThesis/Master-thesis> was used as the working directory.
Started at Tue Nov  8 18:49:59 2022
Terminated at Tue Nov  8 23:17:41 2022
Results reported at Tue Nov  8 23:17:41 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J testjob
#BSUB -n 1
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 05:00
#BSUB -R "rusage[mem=5GB]"
#BSUB -o outputs/gpu_%J.out
#BSUB -e outputs/errors/gpu_%J.err

nvidia-smi
module load cuda/11.6

/appl/cuda/11.6.0/samples/bin/x86_64/linux/release/deviceQuery

source $HOME/miniconda3/bin/activate
source venv_1/bin/activate

python3 main.py Deep_google 128 1e-6 10 400 2_4_test2 7
python3 main.py Deep_google 128 1e-6 10 400 shuffle_test2 99
#python3 main.py CNN_simple 128 1e-6 10 100 2_4 7

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   13414.10 sec.
    Max Memory :                                 2253 MB
    Average Memory :                             2215.30 MB
    Total Requested Memory :                     5120.00 MB
    Delta Memory :                               2867.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   16098 sec.
    Turnaround time :                            16062 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/errors/gpu_14695267.err> for stderr output of this job.

